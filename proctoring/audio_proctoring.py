"""
AudioProctorSystem - –°–∏—Å—Ç–µ–º–∞ –∞—É–¥–∏–æ –ø—Ä–æ–∫—Ç–æ—Ä–∏–Ω–≥–∞ —Å –ò–ò –∏ —É–º–Ω—ã–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
–ú–æ–¥–µ–ª—å Whisper –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –û–î–ò–ù —Ä–∞–∑ –∏ –æ—Å—Ç–∞–µ—Ç—Å—è –≤ –ø–∞–º—è—Ç–∏
"""

import os
import json
import asyncio
import logging
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import tempfile
import base64
import io

# –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞
import librosa
import soundfile as sf
import torch
from scipy.spatial.distance import cosine
from sklearn.preprocessing import StandardScaler

# Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
import whisper

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AudioProctorSystem:
    """
    –°–∏—Å—Ç–µ–º–∞ –∞—É–¥–∏–æ –ø—Ä–æ–∫—Ç–æ—Ä–∏–Ω–≥–∞ —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π –≥–æ–ª–æ—Å–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
    Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –û–î–ò–ù —Ä–∞–∑ –∏ –∫–µ—à–∏—Ä—É–µ—Ç—Å—è
    """
    
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.audio_logs_dir = data_dir / "audio_logs"
        self.audio_logs_dir.mkdir(exist_ok=True)
        
        # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑!)
        self.whisper_model = None
        self._whisper_loaded = False
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        self.is_calibrated = False
        self.candidate_voice_profile = None
        self.calibration_samples = []
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.config = {
            'sample_rate': 16000,
            'calibration_duration': 10,  # —Å–µ–∫—É–Ω–¥
            'min_calibration_samples': 5,
            'similarity_threshold': 0.65,  # –ø–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è "—Å–≤–æ–π/—á—É–∂–æ–π"
            'whisper_model': 'base',  # tiny=–±—ã—Å—Ç—Ä–æ, base=–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ
            'chunk_duration': 2.0,  # —Å–µ–∫—É–Ω–¥ –Ω–∞ —á–∞–Ω–∫
            'mfcc_features': 13,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ MFCC –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤
        }
        
        # –ò—Å—Ç–æ—Ä–∏—è –∞–Ω–∞–ª–∏–∑–∞
        self.analysis_history = []
        
    async def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π (–∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ)"""
        try:
            logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AudioProctorSystem...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper –û–î–ò–ù —Ä–∞–∑
            if not self._whisper_loaded:
                logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ Whisper –º–æ–¥–µ–ª–∏: {self.config['whisper_model']} (–∑–∞–π–º–µ—Ç ~45 —Å–µ–∫)")
                start_time = datetime.now()
                
                self.whisper_model = whisper.load_model(self.config['whisper_model'])
                
                load_time = (datetime.now() - start_time).total_seconds()
                logger.info(f"‚úÖ Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.1f} —Å–µ–∫—É–Ω–¥")
                self._whisper_loaded = True
            else:
                logger.info("‚ôªÔ∏è Whisper –º–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à)")
            
            logger.info("‚úÖ AudioProctorSystem –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return False
    
    def preprocess_audio(self, audio_data: bytes, sample_rate: int = None) -> np.ndarray:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π MP4/WebM/OGG"""
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ –ø–µ—Ä–≤—ã–º –±–∞–π—Ç–∞–º
            file_signature = audio_data[:12]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            if b'ftyp' in file_signature or b'mp4' in file_signature:
                file_ext = '.mp4'
            elif b'OggS' in file_signature:
                file_ext = '.ogg'  
            elif b'webm' in file_signature or b'mkv' in file_signature:
                file_ext = '.webm'
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ–±—É–µ–º –∫–∞–∫ WebM
                file_ext = '.webm'
            
            logger.info(f"üîç –û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_ext}")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
            with tempfile.NamedTemporaryFile(suffix=file_ext, delete=False) as tmp_file:
                tmp_file.write(audio_data)
                tmp_file_path = tmp_file.name
            
            audio = None
            
            try:
                # –°–ø–æ—Å–æ–± 1: Librosa –Ω–∞–ø—Ä—è–º—É—é (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å MP4 –∏ OGG)
                audio, sr = librosa.load(
                    tmp_file_path, 
                    sr=sample_rate or self.config['sample_rate'],
                    mono=True
                )
                logger.info(f"‚úÖ Librosa —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∑–∏–ª–∞ {file_ext}: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                
            except Exception as librosa_error:
                logger.warning(f"Librosa {file_ext} error: {librosa_error}")
                
                # –°–ø–æ—Å–æ–± 2: SoundFile (—Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å MP4/OGG)
                try:
                    import soundfile as sf
                    audio, sr = sf.read(tmp_file_path)
                    
                    if sr != self.config['sample_rate']:
                        audio = librosa.resample(audio, orig_sr=sr, target_sr=self.config['sample_rate'])
                    
                    logger.info(f"‚úÖ SoundFile —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–ª {file_ext}: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                    
                except Exception as sf_error:
                    logger.warning(f"SoundFile {file_ext} error: {sf_error}")
                    
                    # –°–ø–æ—Å–æ–± 3: Pydub (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç ffmpeg –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤)
                    try:
                        from pydub import AudioSegment
                        
                        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ (–∞–≤—Ç–æ–¥–µ—Ç–µ–∫—Ü–∏—è)
                        audio_segment = AudioSegment.from_file(tmp_file_path)
                        
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                        audio_segment = audio_segment.set_frame_rate(self.config['sample_rate'])
                        audio_segment = audio_segment.set_channels(1)  # Mono
                        
                        # –ü–æ–ª—É—á–∞–µ–º raw audio –¥–∞–Ω–Ω—ã–µ
                        raw_data = audio_segment.raw_data
                        audio = np.frombuffer(raw_data, dtype=np.int16).astype(np.float32) / 32768.0
                        
                        logger.info(f"‚úÖ Pydub —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–ª {file_ext}: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                        
                    except Exception as pydub_error:
                        logger.error(f"Pydub {file_ext} –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {pydub_error}")
                        
                        # –°–ø–æ—Å–æ–± 4: –ï—Å–ª–∏ —ç—Ç–æ WebM, –ø—Ä–æ–±—É–µ–º –∫–∞–∫ OGG
                        if file_ext == '.webm':
                            try:
                                ogg_path = tmp_file_path.replace('.webm', '.ogg')
                                os.rename(tmp_file_path, ogg_path)
                                
                                audio, sr = librosa.load(ogg_path, sr=self.config['sample_rate'])
                                logger.info(f"‚úÖ WebM –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∫–∞–∫ OGG: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                                tmp_file_path = ogg_path  # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
                                
                            except Exception as ogg_error:
                                logger.error(f"WebM‚ÜíOGG –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {ogg_error}")
            
            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                for tmp_path in [tmp_file_path, tmp_file_path.replace(file_ext, '.ogg'), tmp_file_path.replace(file_ext, '.wav')]:
                    if os.path.exists(tmp_path):
                        try:
                            os.unlink(tmp_path)
                        except:
                            pass
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if audio is None or len(audio) == 0:
                logger.error(f"üö´ –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª {file_ext}")
                logger.error("üí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:")
                logger.error("   1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–π –±—Ä–∞—É–∑–µ—Ä (Chrome, Firefox, Edge)")
                logger.error("   2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞")
                logger.error("   3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ FFmpeg –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ñ–æ—Ä–º–∞—Ç–æ–≤")
                return np.array([])
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            audio = librosa.util.normalize(audio)
            
            # –£–±–∏—Ä–∞–µ–º —Ç–∏—à–∏–Ω—É (–±–æ–ª–µ–µ –º—è–≥–∫–∞—è –æ–±—Ä–µ–∑–∫–∞)
            try:
                audio, _ = librosa.effects.trim(audio, top_db=20)
            except:
                # –ï—Å–ª–∏ trim –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                pass
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
            min_samples = int(0.3 * self.config['sample_rate'])  # 0.3 —Å–µ–∫—É–Ω–¥—ã
            if len(audio) < min_samples:
                logger.warning(f"–ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ: {len(audio)} —Å—ç–º–ø–ª–æ–≤ ({len(audio)/self.config['sample_rate']:.2f}—Å)")
                return np.array([])
            
            logger.info(f"‚úÖ –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ: {len(audio)/self.config['sample_rate']:.2f}—Å, {len(audio)} —Å—ç–º–ø–ª–æ–≤")
            return audio
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {e}")
            return np.array([])
    
    async def transcribe_audio(self, audio_data: np.ndarray) -> Dict:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper (–ë–´–°–¢–†–û - –º–æ–¥–µ–ª—å —É–∂–µ –≤ –ø–∞–º—è—Ç–∏)"""
        try:
            if not self._whisper_loaded or self.whisper_model is None:
                return {"success": False, "error": "Whisper –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"}
            
            # Whisper –æ–∂–∏–¥–∞–µ—Ç float32
            if audio_data.dtype != np.float32:
                audio_data = audio_data.astype(np.float32)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –∞—É–¥–∏–æ
            if len(audio_data) < self.config['sample_rate'] * 0.1:  # –º–µ–Ω—å—à–µ 0.1 —Å–µ–∫
                return {"success": False, "error": "–ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"}
            
            logger.info(f"üéôÔ∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ: {len(audio_data)/self.config['sample_rate']:.1f} —Å–µ–∫")
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (–ë–´–°–¢–†–û - –º–æ–¥–µ–ª—å —É–∂–µ –≤ –ø–∞–º—è—Ç–∏!)
            start_time = datetime.now()
            result = self.whisper_model.transcribe(
                audio_data,
                language='ru',  # –º–æ–∂–Ω–æ –∞–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç: language=None
                task='transcribe',
                temperature=0.0,  # –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                no_speech_threshold=0.6,
                condition_on_previous_text=False
            )
            
            transcription_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"‚ö° –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {transcription_time:.1f} —Å–µ–∫")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Ç–µ–∫—Å—Ç
            text = result["text"].strip()
            if not text:
                return {"success": False, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"}
            
            return {
                "success": True,
                "text": text,
                "language": result.get("language", "unknown"),
                "confidence": 1.0 - result.get("no_speech_prob", 0.5),
                "processing_time": transcription_time,
                "segments": result.get("segments", [])
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            return {"success": False, "error": str(e)}
    
    def extract_voice_features(self, audio_data: np.ndarray) -> Optional[np.ndarray]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (MFCC) –¥–ª—è speaker identification"""
        try:
            if len(audio_data) == 0:
                return None
            
            # MFCC –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã (–æ—Å–Ω–æ–≤–∞ –¥–ª—è speaker identification)
            mfccs = librosa.feature.mfcc(
                y=audio_data,
                sr=self.config['sample_rate'],
                n_mfcc=self.config['mfcc_features'],
                n_fft=2048,
                hop_length=512
            )
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            features = []
            
            # –°—Ä–µ–¥–Ω–µ–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ MFCC
            features.extend(np.mean(mfccs, axis=1))  # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            features.extend(np.std(mfccs, axis=1))   # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π —Ü–µ–Ω—Ç—Ä–æ–∏–¥ (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ —Ç–µ–º–±—Ä–∞)
            spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=self.config['sample_rate'])
            features.append(np.mean(spectral_centroids))
            features.append(np.std(spectral_centroids))
            
            # Zero crossing rate (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –≥–æ–ª–æ—Å–∞)
            zcr = librosa.feature.zero_crossing_rate(audio_data)
            features.append(np.mean(zcr))
            features.append(np.std(zcr))
            
            # RMS —ç–Ω–µ—Ä–≥–∏—è
            rms = librosa.feature.rms(y=audio_data)
            features.append(np.mean(rms))
            features.append(np.std(rms))
            
            return np.array(features)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return None
    
    async def start_calibration(self, session_id: str) -> Dict:
        """–ù–∞—á–∞–ª–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –≥–æ–ª–æ—Å–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"""
        try:
            logger.info(f"üéØ –ù–∞—á–∏–Ω–∞–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –≥–æ–ª–æ—Å–∞ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ Whisper –∑–∞–≥—Ä—É–∂–µ–Ω
            if not self._whisper_loaded:
                return {"success": False, "error": "–°–∏—Å—Ç–µ–º–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞"}
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            self.calibration_samples = []
            self.is_calibrated = False
            self.candidate_voice_profile = None
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–µ—Å—Å–∏–∏
            session_dir = self.audio_logs_dir / session_id
            session_dir.mkdir(exist_ok=True)
            
            return {
                "success": True,
                "message": "üé§ –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–∞—á–∞—Ç–∞. –ì–æ–≤–æ—Ä–∏—Ç–µ —á–µ—Ç–∫–æ –∏ —Å–ø–æ–∫–æ–π–Ω–æ —É–∫–∞–∑–∞–Ω–Ω—É—é —Ñ—Ä–∞–∑—É.",
                "calibration_phrase": "–ú–µ–Ω—è –∑–æ–≤—É—Ç [–í–∞—à–µ –∏–º—è], —è –ø—Ä–æ—Ö–æ–∂—É —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Halyk Bank –Ω–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞. –≠—Ç–æ –º–æ—è –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–∞—è —Ñ—Ä–∞–∑–∞ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø—Ä–æ–∫—Ç–æ—Ä–∏–Ω–≥–∞. –Ø –≥–æ–≤–æ—Ä—é –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –≥–æ–ª–æ—Å–æ–º.",
                "duration": self.config['calibration_duration'],
                "min_samples": self.config['min_calibration_samples'],
                "session_id": session_id,
                "instructions": [
                    "–ì–æ–≤–æ—Ä–∏—Ç–µ —Å–≤–æ–∏–º –æ–±—ã—á–Ω—ã–º –≥–æ–ª–æ—Å–æ–º",
                    "–ù–µ —à–µ–ø—á–∏—Ç–µ –∏ –Ω–µ –∫—Ä–∏—á–∏—Ç–µ",
                    "–ü–æ–≤—Ç–æ—Ä–∏—Ç–µ —Ñ—Ä–∞–∑—É 2-3 —Ä–∞–∑–∞ —á–µ—Ç–∫–æ",
                    "–ò–∑–±–µ–≥–∞–π—Ç–µ —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞"
                ]
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—á–∞–ª–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: {e}")
            return {"success": False, "error": str(e)}
    
    async def add_calibration_sample(self, session_id: str, audio_data: bytes) -> Dict:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏"""
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
            audio_array = self.preprocess_audio(audio_data)
            
            if len(audio_array) == 0:
                return {"success": False, "error": "–ü—É—Å—Ç—ã–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ"}
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            min_duration = 1.0  # —Å–µ–∫—É–Ω–¥–∞
            actual_duration = len(audio_array) / self.config['sample_rate']
            if actual_duration < min_duration:
                return {
                    "success": False,
                    "error": f"–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∞—É–¥–∏–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç: {actual_duration:.1f}—Å (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º {min_duration}—Å)"
                }
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            features = self.extract_voice_features(audio_array)
            if features is None:
                return {"success": False, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≥–æ–ª–æ—Å–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"}
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é (–ë–´–°–¢–†–û!)
            transcription = await self.transcribe_audio(audio_array)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø–æ–ª—É—á–∏–ª–∞—Å—å
            if not transcription.get("success"):
                return {
                    "success": False,
                    "error": f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {transcription.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
                }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–∑–µ—Ü
            sample = {
                "timestamp": datetime.now().isoformat(),
                "audio_length": actual_duration,
                "features": features.tolist(),
                "transcription": transcription,
                "sample_id": len(self.calibration_samples),
                "feature_quality": "good" if len(features) > 20 else "basic"
            }
            
            self.calibration_samples.append(sample)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
            session_dir = self.audio_logs_dir / session_id
            audio_filename = f"calibration_sample_{len(self.calibration_samples):02d}.wav"
            sf.write(
                session_dir / audio_filename,
                audio_array,
                self.config['sample_rate']
            )
            
            logger.info(f"üì• –î–æ–±–∞–≤–ª–µ–Ω –æ–±—Ä–∞–∑–µ—Ü –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ #{len(self.calibration_samples)}: '{transcription.get('text', 'N/A')[:50]}...' ({actual_duration:.1f}—Å)")
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
            progress = len(self.calibration_samples) / self.config['min_calibration_samples'] * 100
            can_finish = len(self.calibration_samples) >= self.config['min_calibration_samples']
            
            return {
                "success": True,
                "samples_collected": len(self.calibration_samples),
                "min_required": self.config['min_calibration_samples'],
                "progress_percent": min(100, int(progress)),
                "can_finish_calibration": can_finish,
                "transcription": transcription.get('text', ''),
                "audio_length": actual_duration,
                "confidence": transcription.get('confidence', 0.0),
                "processing_time": transcription.get('processing_time', 0.0)
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞: {e}")
            return {"success": False, "error": str(e)}
    
    async def finish_calibration(self, session_id: str) -> Dict:
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è"""
        try:
            if len(self.calibration_samples) < self.config['min_calibration_samples']:
                return {
                    "success": False,
                    "error": f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏. –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º {self.config['min_calibration_samples']}, –µ—Å—Ç—å {len(self.calibration_samples)}"
                }
            
            logger.info(f"üß† –°–æ–∑–¥–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å –∏–∑ {len(self.calibration_samples)} –æ–±—Ä–∞–∑—Ü–æ–≤")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            all_features = []
            good_samples = 0
            
            for sample in self.calibration_samples:
                if sample['features'] and len(sample['features']) > 0:
                    all_features.append(np.array(sample['features']))
                    if sample['transcription'].get('confidence', 0) > 0.7:
                        good_samples += 1
            
            if len(all_features) == 0:
                return {"success": False, "error": "–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"}
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å
            features_matrix = np.array(all_features)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            scaler = StandardScaler()
            normalized_features = scaler.fit_transform(features_matrix)
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            mean_profile = np.mean(normalized_features, axis=0)
            std_profile = np.std(normalized_features, axis=0)
            
            # –í—ã—á–∏—Å–ª—è–µ–º "—ç—Ç–∞–ª–æ–Ω–Ω–æ–µ" —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–≤–Ω—É—Ç—Ä–∏-–∫–ª–∞—Å—Å –≤–∞—Ä–∏–∞—Ü–∏—è)
            intra_class_distances = []
            for i in range(len(normalized_features)):
                distance = cosine(normalized_features[i], mean_profile)
                if not np.isnan(distance):
                    intra_class_distances.append(distance)
            
            avg_intra_distance = np.mean(intra_class_distances) if intra_class_distances else 0.3
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            self.candidate_voice_profile = {
                "mean_features": mean_profile.tolist(),
                "std_features": std_profile.tolist(),
                "scaler_mean": scaler.mean_.tolist(),
                "scaler_scale": scaler.scale_.tolist(),
                "num_samples": len(all_features),
                "good_samples": good_samples,
                "avg_intra_distance": avg_intra_distance,
                "created_at": datetime.now().isoformat(),
                "session_id": session_id,
                "feature_dimension": len(mean_profile),
                "quality_score": good_samples / len(all_features),
                "calibration_config": self.config.copy()
            }
            
            self.is_calibrated = True
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –≤ —Ñ–∞–π–ª
            session_dir = self.audio_logs_dir / session_id
            profile_file = session_dir / "voice_profile.json"
            with open(profile_file, 'w', encoding='utf-8') as f:
                json.dump(self.candidate_voice_profile, f, ensure_ascii=False, indent=2)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º scaler –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            import pickle
            scaler_file = session_dir / "voice_scaler.pkl"
            with open(scaler_file, 'wb') as f:
                pickle.dump(scaler, f)
            
            logger.info("‚úÖ –ì–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
            return {
                "success": True,
                "message": "üéâ –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ì–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ.",
                "profile_stats": {
                    "samples_used": len(all_features),
                    "good_quality_samples": good_samples,
                    "feature_dimension": len(mean_profile),
                    "quality_score": f"{good_samples / len(all_features) * 100:.1f}%",
                    "avg_confidence": avg_intra_distance,
                    "created_at": self.candidate_voice_profile["created_at"]
                },
                "ready_for_testing": True
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: {e}")
            return {"success": False, "error": str(e)}
    
    async def analyze_speech(self, session_id: str, audio_data: bytes) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ—á–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ (–∫—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç + —á—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç)"""
        try:
            if not self.is_calibrated:
                return {"success": False, "error": "–°–∏—Å—Ç–µ–º–∞ –Ω–µ –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–∞"}
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
            audio_array = self.preprocess_audio(audio_data)
            
            if len(audio_array) == 0:
                return {"success": False, "error": "–ü—É—Å—Ç—ã–µ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ"}
            
            actual_duration = len(audio_array) / self.config['sample_rate']
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é (–ë–´–°–¢–†–û!)
            transcription_result = await self.transcribe_audio(audio_array)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–ª–æ—Å–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            current_features = self.extract_voice_features(audio_array)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
            speaker_result = self.identify_speaker(current_features)
            
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            analysis_result = {
                "timestamp": datetime.now().isoformat(),
                "transcription": transcription_result,
                "speaker_identification": speaker_result,
                "audio_length": actual_duration,
                "session_id": session_id,
                "analysis_id": len(self.analysis_history) + 1
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.analysis_history.append(analysis_result)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
            session_dir = self.audio_logs_dir / session_id
            timestamp_str = datetime.now().strftime('%H%M%S_%f')[:-3]  # –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
            audio_filename = f"analysis_{timestamp_str}.wav"
            sf.write(
                session_dir / audio_filename,
                audio_array,
                self.config['sample_rate']
            )
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            is_candidate = speaker_result.get('is_candidate', False)
            confidence = speaker_result.get('confidence', 0) * 100
            text = transcription_result.get('text', 'N/A')[:100]
            processing_time = transcription_result.get('processing_time', 0)
            
            status = "üü¢ –ö–ê–ù–î–ò–î–ê–¢" if is_candidate else "üî¥ –ù–ï –ö–ê–ù–î–ò–î–ê–¢"
            logger.info(f"üé§ {status} ({confidence:.1f}%) [{processing_time:.1f}—Å] - '{text}'")
            
            return {
                "success": True,
                "result": analysis_result
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—á–∏: {e}")
            return {"success": False, "error": str(e)}
    
    def identify_speaker(self, current_features: np.ndarray) -> Dict:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ (–∫–∞–Ω–¥–∏–¥–∞—Ç –∏–ª–∏ –Ω–µ—Ç) - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
        try:
            if not self.is_calibrated or self.candidate_voice_profile is None:
                return {"is_candidate": False, "confidence": 0.0, "error": "–ù–µ –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–æ"}
            
            if current_features is None or len(current_features) == 0:
                return {"is_candidate": False, "confidence": 0.0, "error": "–ù–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"}
            
            # –ü–æ–ª—É—á–∞–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
            mean_profile = np.array(self.candidate_voice_profile['mean_features'])
            scaler_mean = np.array(self.candidate_voice_profile['scaler_mean'])
            scaler_scale = np.array(self.candidate_voice_profile['scaler_scale'])
            
            if len(current_features) != len(mean_profile):
                return {"is_candidate": False, "confidence": 0.0, "error": "–ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"}
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—É—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–µ–º –∂–µ scaler'–æ–º
            normalized_current = (current_features - scaler_mean) / scaler_scale
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å (cosine similarity)
            try:
                cos_distance = cosine(normalized_current, mean_profile)
                if np.isnan(cos_distance):
                    cos_distance = 1.0  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ö–æ–∂–µ—Å—Ç—å (–æ—Ç 0 –¥–æ 1)
                similarity = 1.0 - cos_distance
                similarity = max(0.0, min(1.0, similarity))
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ "–≤–Ω—É—Ç—Ä–∏-–∫–ª–∞—Å—Å" —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
                avg_intra_distance = self.candidate_voice_profile.get('avg_intra_distance', 0.3)
                
                # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
                quality_score = self.candidate_voice_profile.get('quality_score', 0.8)
                adaptive_threshold = self.config['similarity_threshold'] * (0.8 + 0.2 * quality_score)
                
                # –£—á–∏—Ç—ã–≤–∞–µ–º "–≤–Ω—É—Ç—Ä–∏-–∫–ª–∞—Å—Å" –≤–∞—Ä–∏–∞—Ü–∏—é
                if cos_distance <= avg_intra_distance * 1.5:
                    # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π –≤–∞—Ä–∏–∞—Ü–∏–∏ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç
                    confidence_boost = 0.1
                else:
                    confidence_boost = 0.0
                
                final_similarity = similarity + confidence_boost
                is_candidate = final_similarity >= adaptive_threshold
                
                return {
                    "is_candidate": is_candidate,
                    "confidence": final_similarity,
                    "raw_similarity": similarity,
                    "cosine_distance": cos_distance,
                    "threshold": adaptive_threshold,
                    "intra_class_distance": avg_intra_distance,
                    "method": "cosine_similarity_adaptive",
                    "quality_score": quality_score
                }
                
            except Exception as calc_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏: {calc_error}")
                return {"is_candidate": False, "confidence": 0.0, "error": f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π: {calc_error}"}
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ: {e}")
            return {"is_candidate": False, "confidence": 0.0, "error": str(e)}
    
    async def get_session_logs(self, session_id: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ —Å–µ—Å—Å–∏–∏"""
        try:
            session_dir = self.audio_logs_dir / session_id
            
            if not session_dir.exists():
                return {"success": False, "error": "–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
            
            # –ß–∏—Ç–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å (–µ—Å–ª–∏ –µ—Å—Ç—å)
            voice_profile = None
            profile_file = session_dir / "voice_profile.json"
            if profile_file.exists():
                with open(profile_file, 'r', encoding='utf-8') as f:
                    voice_profile = json.load(f)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª—ã
            audio_files = list(session_dir.glob("*.wav"))
            calibration_files = [f for f in audio_files if "calibration" in f.name]
            analysis_files = [f for f in audio_files if "analysis" in f.name]
            
            return {
                "success": True,
                "session_id": session_id,
                "voice_profile": voice_profile,
                "calibration_files": [f.name for f in calibration_files],
                "analysis_files": [f.name for f in analysis_files],
                "total_audio_files": len(audio_files),
                "analysis_history": self.analysis_history[-20:],  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20
                "is_calibrated": self.is_calibrated,
                "total_samples": len(self.calibration_samples),
                "system_stats": self.get_system_stats()
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–≥–æ–≤: {e}")
            return {"success": False, "error": str(e)}
    
    def get_system_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
        return {
            "whisper_model": self.config['whisper_model'],
            "whisper_loaded": self._whisper_loaded,
            "is_calibrated": self.is_calibrated,
            "calibration_samples": len(self.calibration_samples),
            "analysis_history": len(self.analysis_history),
            "config": self.config,
            "voice_profile_quality": self.candidate_voice_profile.get('quality_score', 0.0) if self.candidate_voice_profile else 0.0
        }
    
    def reset_system(self):
        """–°–±—Ä–æ—Å —Å–∏—Å—Ç–µ–º—ã (–æ—á–∏—Å—Ç–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏)"""
        logger.info("üîÑ –°–±—Ä–æ—Å —Å–∏—Å—Ç–µ–º—ã AudioProctorSystem")
        self.is_calibrated = False
        self.candidate_voice_profile = None
        self.calibration_samples = []
        self.analysis_history = []

# === –ì–õ–û–ë–ê–õ–¨–ù–´–ô –≠–ö–ó–ï–ú–ü–õ–Ø–† –° –ö–ï–®–ò–†–û–í–ê–ù–ò–ï–ú ===
_global_audio_proctor = None

async def get_audio_proctor(data_dir: Path) -> AudioProctorSystem:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ AudioProctorSystem (—Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏)"""
    global _global_audio_proctor
    
    if _global_audio_proctor is None:
        logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ AudioProctorSystem")
        _global_audio_proctor = AudioProctorSystem(data_dir)
        success = await _global_audio_proctor.initialize()
        
        if not success:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å AudioProctorSystem")
            _global_audio_proctor = None
            raise RuntimeError("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ —Å–∏—Å—Ç–µ–º—ã")
        
        logger.info("‚úÖ –ì–ª–æ–±–∞–ª—å–Ω—ã–π AudioProctorSystem –≥–æ—Ç–æ–≤")
    
    return _global_audio_proctor

# === –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ===

def audio_bytes_to_numpy(audio_bytes: bytes, sample_rate: int = 16000) -> np.ndarray:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è bytes –≤ numpy array"""
    try:
        audio_io = io.BytesIO(audio_bytes)
        audio, sr = librosa.load(audio_io, sr=sample_rate)
        return librosa.util.normalize(audio)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        return np.array([])

def base64_to_audio(base64_data: str, sample_rate: int = 16000) -> np.ndarray:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è base64 –≤ numpy array"""
    try:
        audio_bytes = base64.b64decode(base64_data)
        return audio_bytes_to_numpy(audio_bytes, sample_rate)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è base64: {e}")
        return np.array([])

# === –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –°–ò–°–¢–ï–ú–´ ===
if __name__ == "__main__":
    async def test_system():
        """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã"""
        from pathlib import Path
        
        print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AudioProctorSystem...")
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
        system = AudioProctorSystem(Path("test_data"))
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º (–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏)
        print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper –º–æ–¥–µ–ª—å...")
        if await system.initialize():
            print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {system.get_system_stats()}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞
            if system._whisper_loaded:
                print("‚ôªÔ∏è –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–π)...")
                start_time = datetime.now()
                await system.initialize()
                load_time = (datetime.now() - start_time).total_seconds()
                print(f"‚ö° –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞ {load_time:.2f} —Å–µ–∫ (–∫–µ—à —Ä–∞–±–æ—Ç–∞–µ—Ç!)")
            
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏")
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
    asyncio.run(test_system())