"""
AudioProctorSystem - –°–∏—Å—Ç–µ–º–∞ –∞—É–¥–∏–æ –ø—Ä–æ–∫—Ç–æ—Ä–∏–Ω–≥–∞ —Å –ò–ò –∏ —É–º–Ω—ã–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
–ú–æ–¥–µ–ª—å Whisper –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –û–î–ò–ù —Ä–∞–∑ –∏ –æ—Å—Ç–∞–µ—Ç—Å—è –≤ –ø–∞–º—è—Ç–∏
–ò–°–ü–†–ê–í–õ–ï–ù–ê –û–ë–†–ê–ë–û–¢–ö–ê WEBM –ë–ï–ó FFMPEG
"""

import os
import json
import asyncio
import logging
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import tempfile
import base64
import io
import subprocess
import shutil

# –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞
import librosa
import soundfile as sf
import torch
from scipy.spatial.distance import cosine
from sklearn.preprocessing import StandardScaler

# Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
import whisper

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AudioProctorSystem:
    """
    –°–∏—Å—Ç–µ–º–∞ –∞—É–¥–∏–æ –ø—Ä–æ–∫—Ç–æ—Ä–∏–Ω–≥–∞ —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π –≥–æ–ª–æ—Å–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
    Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –û–î–ò–ù —Ä–∞–∑ –∏ –∫–µ—à–∏—Ä—É–µ—Ç—Å—è
    –£–õ–£–ß–®–ï–ù–ê –û–ë–†–ê–ë–û–¢–ö–ê WEBM –§–ê–ô–õ–û–í
    """
    
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.audio_logs_dir = data_dir / "audio_logs"
        self.audio_logs_dir.mkdir(exist_ok=True)
        
        # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑!)
        self.whisper_model = None
        self._whisper_loaded = False
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        self.is_calibrated = False
        self.candidate_voice_profile = None
        self.calibration_samples = []
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.config = {
            'sample_rate': 16000,
            'calibration_duration': 10,  # —Å–µ–∫—É–Ω–¥
            'min_calibration_samples': 5,
            'similarity_threshold': 0.65,  # –ø–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è "—Å–≤–æ–π/—á—É–∂–æ–π"
            'whisper_model': 'base',  # tiny=–±—ã—Å—Ç—Ä–æ, base=–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ
            'chunk_duration': 2.0,  # —Å–µ–∫—É–Ω–¥ –Ω–∞ —á–∞–Ω–∫
            'mfcc_features': 13,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ MFCC –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤
        }
        
        # –ò—Å—Ç–æ—Ä–∏—è –∞–Ω–∞–ª–∏–∑–∞
        self.analysis_history = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤–Ω–µ—à–Ω–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        self._check_external_tools()

            
    def _check_external_tools(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤–Ω–µ—à–Ω–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏"""
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ PATH
        self.ffmpeg_available = shutil.which('ffmpeg') is not None
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ PATH, –ø—Ä–æ–±—É–µ–º –ø—Ä—è–º–æ–π –ø—É—Ç—å
        if not self.ffmpeg_available:
            ffmpeg_path = r"C:\ffmpeg\ffmpeg-2025-09-04-git-2611874a50-full_build\ffmpeg-2025-09-04-git-2611874a50-full_build\bin\ffmpeg.exe"
            self.ffmpeg_available = os.path.exists(ffmpeg_path)
            if self.ffmpeg_available:
                self.ffmpeg_executable = ffmpeg_path
        
        self.ffprobe_available = shutil.which('ffprobe') is not None
        
        if self.ffmpeg_available:
            logger.info("‚úÖ FFmpeg –Ω–∞–π–¥–µ–Ω - —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤–∫–ª—é—á–µ–Ω–∞")
        else:
            logger.info("‚ö†Ô∏è FFmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã")
    
    async def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π (–∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ)"""
        try:
            logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AudioProctorSystem...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper –û–î–ò–ù —Ä–∞–∑
            if not self._whisper_loaded:
                logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ Whisper –º–æ–¥–µ–ª–∏: {self.config['whisper_model']} (–∑–∞–π–º–µ—Ç ~45 —Å–µ–∫)")
                start_time = datetime.now()
                
                self.whisper_model = whisper.load_model(self.config['whisper_model'])
                
                load_time = (datetime.now() - start_time).total_seconds()
                logger.info(f"‚úÖ Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.1f} —Å–µ–∫—É–Ω–¥")
                self._whisper_loaded = True
            else:
                logger.info("‚ôªÔ∏è Whisper –º–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à)")
            
            logger.info("‚úÖ AudioProctorSystem –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return False
    
    def detect_audio_format(self, audio_data: bytes) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞"""
        if len(audio_data) < 12:
            return '.unknown'
        
        # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ –±–∞–π—Ç—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞
        header = audio_data[:12]
        
        # MP4/M4A —Å–∏–≥–Ω–∞—Ç—É—Ä—ã
        if b'ftyp' in header or b'M4A ' in header or b'mp41' in header or b'mp42' in header:
            return '.mp4'
        
        # OGG —Å–∏–≥–Ω–∞—Ç—É—Ä–∞
        if header.startswith(b'OggS'):
            return '.ogg'
        
        # WebM —Å–∏–≥–Ω–∞—Ç—É—Ä—ã (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
        if (b'\x1a\x45\xdf\xa3' in header or  # EBML header
            b'webm' in header[:50] or
            b'matroska' in header[:50]):
            return '.webm'
        
        # WAV —Å–∏–≥–Ω–∞—Ç—É—Ä–∞
        if header.startswith(b'RIFF') and b'WAVE' in header:
            return '.wav'
        
        # FLAC —Å–∏–≥–Ω–∞—Ç—É—Ä–∞
        if header.startswith(b'fLaC'):
            return '.flac'
        
        # MP3 —Å–∏–≥–Ω–∞—Ç—É—Ä—ã
        if header.startswith(b'ID3') or header.startswith(b'\xff\xfb'):
            return '.mp3'
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º WebM (—á–∞—Å—Ç–æ –±—Ä–∞—É–∑–µ—Ä –Ω–µ —Å—Ç–∞–≤–∏—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏)
        logger.warning(f"üîç –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç, –ø–µ—Ä–≤—ã–µ 12 –±–∞–π—Ç: {header.hex()}")
        return '.webm'
    
    def preprocess_audio(self, audio_data: bytes, sample_rate: int = None) -> np.ndarray:
        """–£–õ–£–ß–®–ï–ù–ù–ê–Ø –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π WebM"""
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
            file_ext = self.detect_audio_format(audio_data)
            logger.info(f"üîç –û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_ext}")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
            with tempfile.NamedTemporaryFile(suffix=file_ext, delete=False) as tmp_file:
                tmp_file.write(audio_data)
                tmp_file_path = tmp_file.name
            
            audio = None
            success_method = None
            
            try:
                # –ú–ï–¢–û–î 1: –ü—Ä—è–º–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ librosa (–ª—É—á—à–µ –≤—Å–µ–≥–æ –¥–ª—è MP4/WAV/FLAC)
                if file_ext in ['.mp4', '.wav', '.flac', '.mp3']:
                    try:
                        audio, sr = librosa.load(
                            tmp_file_path, 
                            sr=sample_rate or self.config['sample_rate'],
                            mono=True
                        )
                        success_method = f"librosa (native {file_ext})"
                        logger.info(f"‚úÖ {success_method}: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                    except Exception as e:
                        logger.warning(f"Librosa {file_ext} error: {e}")
                
                # –ú–ï–¢–û–î 2: SoundFile –¥–ª—è OGG –∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö MP4
                if audio is None and file_ext in ['.ogg', '.mp4', '.wav']:
                    try:
                        audio_sf, sr = sf.read(tmp_file_path)
                        
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–æ–Ω–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                        if len(audio_sf.shape) > 1:
                            audio_sf = np.mean(audio_sf, axis=1)
                        
                        # –†–µ—Å–µ–º–ø–ª–∏–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                        target_sr = sample_rate or self.config['sample_rate']
                        if sr != target_sr:
                            audio = librosa.resample(audio_sf, orig_sr=sr, target_sr=target_sr)
                        else:
                            audio = audio_sf
                        
                        success_method = f"soundfile {file_ext}"
                        logger.info(f"‚úÖ {success_method}: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                    except Exception as e:
                        logger.warning(f"SoundFile {file_ext} error: {e}")
                
                # –ú–ï–¢–û–î 3: PyDub —Å FFmpeg (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
                if audio is None and self.ffmpeg_available:
                    try:
                        from pydub import AudioSegment
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è PyDub
                        format_map = {
                            '.webm': 'webm',
                            '.ogg': 'ogg', 
                            '.mp4': 'mp4',
                            '.wav': 'wav',
                            '.mp3': 'mp3'
                        }
                        
                        pydub_format = format_map.get(file_ext, 'webm')
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ—Ä–µ–∑ PyDub
                        audio_segment = AudioSegment.from_file(tmp_file_path, format=pydub_format)
                        
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                        audio_segment = audio_segment.set_frame_rate(self.config['sample_rate'])
                        audio_segment = audio_segment.set_channels(1)  # Mono
                        
                        # –ü–æ–ª—É—á–∞–µ–º raw audio –¥–∞–Ω–Ω—ã–µ
                        raw_data = audio_segment.raw_data
                        audio = np.frombuffer(raw_data, dtype=np.int16).astype(np.float32) / 32768.0
                        
                        success_method = f"pydub+ffmpeg {file_ext}"
                        logger.info(f"‚úÖ {success_method}: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                    except Exception as e:
                        logger.warning(f"PyDub {file_ext} error: {e}")
                
                # –ú–ï–¢–û–î 4: –ü—Ä—è–º–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ FFmpeg (–¥–ª—è WebM)
                if audio is None and self.ffmpeg_available and file_ext == '.webm':
                    try:
                        audio = self._convert_webm_with_ffmpeg(tmp_file_path)
                        if audio is not None and len(audio) > 0:
                            success_method = "ffmpeg direct conversion"
                            logger.info(f"‚úÖ {success_method}: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                    except Exception as e:
                        logger.warning(f"FFmpeg direct conversion error: {e}")
                
                # –ú–ï–¢–û–î 5: WebM –∫–∞–∫ OGG (–ø—Ä–æ—Å—Ç–æ–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ + –±–∏–±–ª–∏–æ—Ç–µ–∫–∏)
                if audio is None and file_ext == '.webm':
                    try:
                        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∫–∞–∫ OGG
                        ogg_path = tmp_file_path.replace('.webm', '.ogg')
                        shutil.copy2(tmp_file_path, ogg_path)
                        
                        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞–∫ OGG
                        try:
                            audio, sr = librosa.load(ogg_path, sr=self.config['sample_rate'])
                            success_method = "webm as ogg (librosa)"
                            logger.info(f"‚úÖ {success_method}: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                        except:
                            try:
                                audio_sf, sr = sf.read(ogg_path)
                                if len(audio_sf.shape) > 1:
                                    audio_sf = np.mean(audio_sf, axis=1)
                                if sr != self.config['sample_rate']:
                                    audio = librosa.resample(audio_sf, orig_sr=sr, target_sr=self.config['sample_rate'])
                                else:
                                    audio = audio_sf
                                success_method = "webm as ogg (soundfile)"
                                logger.info(f"‚úÖ {success_method}: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                            except Exception as e2:
                                logger.warning(f"WebM as OGG failed: {e2}")
                        
                        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π OGG —Ñ–∞–π–ª
                        try:
                            os.unlink(ogg_path)
                        except:
                            pass
                    except Exception as e:
                        logger.warning(f"WebM‚ÜíOGG method failed: {e}")
                
                # –ú–ï–¢–û–î 6: –ü–æ–ø—ã—Ç–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–∫ raw PCM (–ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å)
                if audio is None and file_ext == '.webm':
                    try:
                        audio = self._try_raw_pcm_extraction(audio_data)
                        if audio is not None and len(audio) > 0:
                            success_method = "raw PCM extraction"
                            logger.info(f"‚úÖ {success_method}: {len(audio)} —Å—ç–º–ø–ª–æ–≤")
                    except Exception as e:
                        logger.warning(f"Raw PCM extraction failed: {e}")
            
            finally:
                # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                temp_files = [
                    tmp_file_path,
                    tmp_file_path.replace('.webm', '.ogg'),
                    tmp_file_path.replace('.webm', '.wav'),
                    tmp_file_path + '.wav'
                ]
                
                for temp_file in temp_files:
                    if os.path.exists(temp_file):
                        try:
                            os.unlink(temp_file)
                        except:
                            pass
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if audio is None or len(audio) == 0:
                logger.error(f"üö´ –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª {file_ext}")
                logger.error("üí° –ü–æ–ø—Ä–æ–±–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã:")
                logger.error("   1. librosa (native)")
                logger.error("   2. soundfile")
                if self.ffmpeg_available:
                    logger.error("   3. pydub + ffmpeg")
                    logger.error("   4. ffmpeg direct")
                else:
                    logger.error("   3. pydub (FFmpeg –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)")
                logger.error("   5. webm as ogg")
                logger.error("   6. raw PCM extraction")
                logger.error("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
                logger.error("   ‚Ä¢ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ FFmpeg –¥–ª—è –ª—É—á—à–µ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ WebM")
                logger.error("   ‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –±—Ä–∞—É–∑–µ—Ä (Chrome ‚Üí Firefox)")
                logger.error("   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞")
                return np.array([])
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            audio = librosa.util.normalize(audio)
            
            # –£–±–∏—Ä–∞–µ–º —Ç–∏—à–∏–Ω—É (–±–æ–ª–µ–µ –º—è–≥–∫–∞—è –æ–±—Ä–µ–∑–∫–∞)
            try:
                audio, _ = librosa.effects.trim(audio, top_db=20)
            except:
                # –ï—Å–ª–∏ trim –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                pass
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
            min_samples = int(0.3 * self.config['sample_rate'])  # 0.3 —Å–µ–∫—É–Ω–¥—ã
            if len(audio) < min_samples:
                logger.warning(f"–ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ: {len(audio)} —Å—ç–º–ø–ª–æ–≤ ({len(audio)/self.config['sample_rate']:.2f}—Å)")
                return np.array([])
            
            duration = len(audio)/self.config['sample_rate']
            logger.info(f"‚úÖ –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ ({success_method}): {duration:.2f}—Å, {len(audio)} —Å—ç–º–ø–ª–æ–≤")
            return audio
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {e}")
            return np.array([])
        
    def _convert_webm_with_ffmpeg(self, input_path: str) -> Optional[np.ndarray]:
        """–ü—Ä—è–º–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è WebM —á–µ—Ä–µ–∑ FFmpeg –≤ WAV"""
        try:
            output_path = input_path + '_converted.wav'
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –ø—É—Ç—å –∫ FFmpeg –∏–ª–∏ –∫–æ–º–∞–Ω–¥—É –∏–∑ PATH
            if hasattr(self, 'ffmpeg_executable'):
                ffmpeg_cmd = self.ffmpeg_executable
            else:
                ffmpeg_cmd = 'ffmpeg'
            
            cmd = [
                ffmpeg_cmd,
                '-i', input_path,
                '-acodec', 'pcm_s16le',
                '-ar', str(self.config['sample_rate']),
                '-ac', '1',
                '-y',
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0 and os.path.exists(output_path):
                audio, sr = librosa.load(output_path, sr=self.config['sample_rate'])
                os.unlink(output_path)
                return audio
            else:
                logger.warning(f"FFmpeg conversion failed: {result.stderr}")
                return None
                
        except Exception as e:
            logger.warning(f"FFmpeg conversion error: {e}")
            return None
    
    
    def _try_raw_pcm_extraction(self, audio_data: bytes) -> Optional[np.ndarray]:
        """–ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å PCM –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ WebM (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥)"""
        try:
            # –ò—â–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ PCM –¥–∞–Ω–Ω—ã–µ –≤ WebM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
            # –≠—Ç–æ –æ—á–µ–Ω—å —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥, –Ω–æ –º–æ–∂–µ—Ç —Å—Ä–∞–±–æ—Ç–∞—Ç—å –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö WebM —Ñ–∞–π–ª–æ–≤
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ WebM (–ø—Ä–∏–º–µ—Ä–Ω–æ –ø–µ—Ä–≤—ã–µ 100-500 –±–∞–π—Ç)
            for skip_bytes in [100, 200, 500, 1000]:
                if len(audio_data) <= skip_bytes:
                    continue
                
                try:
                    # –ü—ã—Ç–∞–µ–º—Å—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ 16-bit PCM
                    raw_audio = audio_data[skip_bytes:]
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–ª–∏–Ω–∞ —á–µ—Ç–Ω–∞—è (–¥–ª—è 16-bit –¥–∞–Ω–Ω—ã—Ö)
                    if len(raw_audio) % 2 != 0:
                        raw_audio = raw_audio[:-1]
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array
                    audio_int16 = np.frombuffer(raw_audio, dtype=np.int16)
                    
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ float32
                    audio_float = audio_int16.astype(np.float32) / 32768.0
                    
                    # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∞—É–¥–∏–æ
                    if len(audio_float) > 1000:  # –ú–∏–Ω–∏–º—É–º 1000 —Å—ç–º–ø–ª–æ–≤
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–º–∏ (–Ω–µ —Ç–∏—à–∏–Ω–∞)
                        if np.std(audio_float) > 0.01:
                            logger.info(f"Raw PCM extraction: –Ω–∞–π–¥–µ–Ω–æ {len(audio_float)} —Å—ç–º–ø–ª–æ–≤ (–ø—Ä–æ–ø—É—Å–∫ {skip_bytes} –±–∞–π—Ç)")
                            return audio_float
                    
                except Exception:
                    continue
            
            return None
            
        except Exception as e:
            logger.warning(f"Raw PCM extraction failed: {e}")
            return None
    
    async def transcribe_audio(self, audio_data: np.ndarray) -> Dict:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper (–ë–´–°–¢–†–û - –º–æ–¥–µ–ª—å —É–∂–µ –≤ –ø–∞–º—è—Ç–∏)"""
        try:
            if not self._whisper_loaded or self.whisper_model is None:
                return {"success": False, "error": "Whisper –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"}
            
            # Whisper –æ–∂–∏–¥–∞–µ—Ç float32
            if audio_data.dtype != np.float32:
                audio_data = audio_data.astype(np.float32)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –∞—É–¥–∏–æ
            if len(audio_data) < self.config['sample_rate'] * 0.1:  # –º–µ–Ω—å—à–µ 0.1 —Å–µ–∫
                return {"success": False, "error": "–ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"}
            
            logger.info(f"üéôÔ∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ: {len(audio_data)/self.config['sample_rate']:.1f} —Å–µ–∫")
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (–ë–´–°–¢–†–û - –º–æ–¥–µ–ª—å —É–∂–µ –≤ –ø–∞–º—è—Ç–∏!)
            start_time = datetime.now()
            result = self.whisper_model.transcribe(
                audio_data,
                language='ru',  # –º–æ–∂–Ω–æ –∞–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç: language=None
                task='transcribe',
                temperature=0.0,  # –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                no_speech_threshold=0.6,
                condition_on_previous_text=False
            )
            
            transcription_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"‚ö° –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {transcription_time:.1f} —Å–µ–∫")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Ç–µ–∫—Å—Ç
            text = result["text"].strip()
            if not text:
                return {"success": False, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"}
            
            return {
                "success": True,
                "text": text,
                "language": result.get("language", "unknown"),
                "confidence": 1.0 - result.get("no_speech_prob", 0.5),
                "processing_time": transcription_time,
                "segments": result.get("segments", [])
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            return {"success": False, "error": str(e)}
    
    def extract_voice_features(self, audio_data: np.ndarray) -> Optional[np.ndarray]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (MFCC) –¥–ª—è speaker identification"""
        try:
            if len(audio_data) == 0:
                return None
            
            # MFCC –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã (–æ—Å–Ω–æ–≤–∞ –¥–ª—è speaker identification)
            mfccs = librosa.feature.mfcc(
                y=audio_data,
                sr=self.config['sample_rate'],
                n_mfcc=self.config['mfcc_features'],
                n_fft=2048,
                hop_length=512
            )
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            features = []
            
            # –°—Ä–µ–¥–Ω–µ–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ MFCC
            features.extend(np.mean(mfccs, axis=1))  # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            features.extend(np.std(mfccs, axis=1))   # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π —Ü–µ–Ω—Ç—Ä–æ–∏–¥ (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ —Ç–µ–º–±—Ä–∞)
            spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=self.config['sample_rate'])
            features.append(np.mean(spectral_centroids))
            features.append(np.std(spectral_centroids))
            
            # Zero crossing rate (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –≥–æ–ª–æ—Å–∞)
            zcr = librosa.feature.zero_crossing_rate(audio_data)
            features.append(np.mean(zcr))
            features.append(np.std(zcr))
            
            # RMS —ç–Ω–µ—Ä–≥–∏—è
            rms = librosa.feature.rms(y=audio_data)
            features.append(np.mean(rms))
            features.append(np.std(rms))
            
            return np.array(features)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return None
    
    async def start_calibration(self, session_id: str) -> Dict:
        """–ù–∞—á–∞–ª–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –≥–æ–ª–æ—Å–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"""
        try:
            logger.info(f"üéØ –ù–∞—á–∏–Ω–∞–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –≥–æ–ª–æ—Å–∞ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ Whisper –∑–∞–≥—Ä—É–∂–µ–Ω
            if not self._whisper_loaded:
                return {"success": False, "error": "–°–∏—Å—Ç–µ–º–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞"}
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            self.calibration_samples = []
            self.is_calibrated = False
            self.candidate_voice_profile = None
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–µ—Å—Å–∏–∏
            session_dir = self.audio_logs_dir / session_id
            session_dir.mkdir(exist_ok=True)
            
            return {
                "success": True,
                "message": "üé§ –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–∞—á–∞—Ç–∞. –ì–æ–≤–æ—Ä–∏—Ç–µ —á–µ—Ç–∫–æ –∏ —Å–ø–æ–∫–æ–π–Ω–æ —É–∫–∞–∑–∞–Ω–Ω—É—é —Ñ—Ä–∞–∑—É.",
                "calibration_phrase": "–ú–µ–Ω—è –∑–æ–≤—É—Ç [–í–∞—à–µ –∏–º—è], —è –ø—Ä–æ—Ö–æ–∂—É —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Halyk Bank –Ω–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞. –≠—Ç–æ –º–æ—è –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–∞—è —Ñ—Ä–∞–∑–∞ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø—Ä–æ–∫—Ç–æ—Ä–∏–Ω–≥–∞. –Ø –≥–æ–≤–æ—Ä—é –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –≥–æ–ª–æ—Å–æ–º.",
                "duration": self.config['calibration_duration'],
                "min_samples": self.config['min_calibration_samples'],
                "session_id": session_id,
                "instructions": [
                    "–ì–æ–≤–æ—Ä–∏—Ç–µ —Å–≤–æ–∏–º –æ–±—ã—á–Ω—ã–º –≥–æ–ª–æ—Å–æ–º",
                    "–ù–µ —à–µ–ø—á–∏—Ç–µ –∏ –Ω–µ –∫—Ä–∏—á–∏—Ç–µ",
                    "–ü–æ–≤—Ç–æ—Ä–∏—Ç–µ —Ñ—Ä–∞–∑—É 2-3 —Ä–∞–∑–∞ —á–µ—Ç–∫–æ",
                    "–ò–∑–±–µ–≥–∞–π—Ç–µ —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞"
                ]
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—á–∞–ª–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: {e}")
            return {"success": False, "error": str(e)}
    
    async def add_calibration_sample(self, session_id: str, audio_data: bytes) -> Dict:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏"""
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
            audio_array = self.preprocess_audio(audio_data)
            
            if len(audio_array) == 0:
                return {"success": False, "error": "–ü—É—Å—Ç—ã–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ"}
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            min_duration = 1.0  # —Å–µ–∫—É–Ω–¥–∞
            actual_duration = len(audio_array) / self.config['sample_rate']
            if actual_duration < min_duration:
                return {
                    "success": False,
                    "error": f"–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∞—É–¥–∏–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç: {actual_duration:.1f}—Å (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º {min_duration}—Å)"
                }
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            features = self.extract_voice_features(audio_array)
            if features is None:
                return {"success": False, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≥–æ–ª–æ—Å–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"}
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é (–ë–´–°–¢–†–û!)
            transcription = await self.transcribe_audio(audio_array)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø–æ–ª—É—á–∏–ª–∞—Å—å
            if not transcription.get("success"):
                return {
                    "success": False,
                    "error": f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {transcription.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
                }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–∑–µ—Ü
            sample = {
                "timestamp": datetime.now().isoformat(),
                "audio_length": actual_duration,
                "features": features.tolist(),
                "transcription": transcription,
                "sample_id": len(self.calibration_samples),
                "feature_quality": "good" if len(features) > 20 else "basic"
            }
            
            self.calibration_samples.append(sample)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
            session_dir = self.audio_logs_dir / session_id
            audio_filename = f"calibration_sample_{len(self.calibration_samples):02d}.wav"
            sf.write(
                session_dir / audio_filename,
                audio_array,
                self.config['sample_rate']
            )
            
            logger.info(f"üì• –î–æ–±–∞–≤–ª–µ–Ω –æ–±—Ä–∞–∑–µ—Ü –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ #{len(self.calibration_samples)}: '{transcription.get('text', 'N/A')[:50]}...' ({actual_duration:.1f}—Å)")
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
            progress = len(self.calibration_samples) / self.config['min_calibration_samples'] * 100
            can_finish = len(self.calibration_samples) >= self.config['min_calibration_samples']
            
            return {
                "success": True,
                "samples_collected": len(self.calibration_samples),
                "min_required": self.config['min_calibration_samples'],
                "progress_percent": min(100, int(progress)),
                "can_finish_calibration": can_finish,
                "transcription": transcription.get('text', ''),
                "audio_length": actual_duration,
                "confidence": transcription.get('confidence', 0.0),
                "processing_time": transcription.get('processing_time', 0.0)
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞: {e}")
            return {"success": False, "error": str(e)}
    
    async def finish_calibration(self, session_id: str) -> Dict:
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è"""
        try:
            if len(self.calibration_samples) < self.config['min_calibration_samples']:
                return {
                    "success": False,
                    "error": f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏. –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º {self.config['min_calibration_samples']}, –µ—Å—Ç—å {len(self.calibration_samples)}"
                }
            
            logger.info(f"üß† –°–æ–∑–¥–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å –∏–∑ {len(self.calibration_samples)} –æ–±—Ä–∞–∑—Ü–æ–≤")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            all_features = []
            good_samples = 0
            
            for sample in self.calibration_samples:
                if sample['features'] and len(sample['features']) > 0:
                    all_features.append(np.array(sample['features']))
                    if sample['transcription'].get('confidence', 0) > 0.7:
                        good_samples += 1
            
            if len(all_features) == 0:
                return {"success": False, "error": "–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"}
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å
            features_matrix = np.array(all_features)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            scaler = StandardScaler()
            normalized_features = scaler.fit_transform(features_matrix)
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            mean_profile = np.mean(normalized_features, axis=0)
            std_profile = np.std(normalized_features, axis=0)
            
            # –í—ã—á–∏—Å–ª—è–µ–º "—ç—Ç–∞–ª–æ–Ω–Ω–æ–µ" —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–≤–Ω—É—Ç—Ä–∏-–∫–ª–∞—Å—Å –≤–∞—Ä–∏–∞—Ü–∏—è)
            intra_class_distances = []
            for i in range(len(normalized_features)):
                distance = cosine(normalized_features[i], mean_profile)
                if not np.isnan(distance):
                    intra_class_distances.append(distance)
            
            avg_intra_distance = np.mean(intra_class_distances) if intra_class_distances else 0.3
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            self.candidate_voice_profile = {
                "mean_features": mean_profile.tolist(),
                "std_features": std_profile.tolist(),
                "scaler_mean": scaler.mean_.tolist(),
                "scaler_scale": scaler.scale_.tolist(),
                "num_samples": len(all_features),
                "good_samples": good_samples,
                "avg_intra_distance": avg_intra_distance,
                "created_at": datetime.now().isoformat(),
                "session_id": session_id,
                "feature_dimension": len(mean_profile),
                "quality_score": good_samples / len(all_features),
                "calibration_config": self.config.copy()
            }
            
            self.is_calibrated = True
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –≤ —Ñ–∞–π–ª
            session_dir = self.audio_logs_dir / session_id
            profile_file = session_dir / "voice_profile.json"
            with open(profile_file, 'w', encoding='utf-8') as f:
                json.dump(self.candidate_voice_profile, f, ensure_ascii=False, indent=2)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º scaler –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            import pickle
            scaler_file = session_dir / "voice_scaler.pkl"
            with open(scaler_file, 'wb') as f:
                pickle.dump(scaler, f)
            
            logger.info("‚úÖ –ì–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
            return {
                "success": True,
                "message": "üéâ –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ì–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ.",
                "profile_stats": {
                    "samples_used": len(all_features),
                    "good_quality_samples": good_samples,
                    "feature_dimension": len(mean_profile),
                    "quality_score": f"{good_samples / len(all_features) * 100:.1f}%",
                    "avg_confidence": avg_intra_distance,
                    "created_at": self.candidate_voice_profile["created_at"]
                },
                "ready_for_testing": True
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: {e}")
            return {"success": False, "error": str(e)}
    
    async def analyze_speech(self, session_id: str, audio_data: bytes) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ—á–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ (–∫—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç + —á—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç)"""
        try:
            if not self.is_calibrated:
                return {"success": False, "error": "–°–∏—Å—Ç–µ–º–∞ –Ω–µ –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–∞"}
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
            audio_array = self.preprocess_audio(audio_data)
            
            if len(audio_array) == 0:
                return {"success": False, "error": "–ü—É—Å—Ç—ã–µ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ"}
            
            actual_duration = len(audio_array) / self.config['sample_rate']
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é (–ë–´–°–¢–†–û!)
            transcription_result = await self.transcribe_audio(audio_array)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–ª–æ—Å–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            current_features = self.extract_voice_features(audio_array)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
            speaker_result = self.identify_speaker(current_features)
            
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            analysis_result = {
                "timestamp": datetime.now().isoformat(),
                "transcription": transcription_result,
                "speaker_identification": speaker_result,
                "audio_length": actual_duration,
                "session_id": session_id,
                "analysis_id": len(self.analysis_history) + 1
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.analysis_history.append(analysis_result)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
            session_dir = self.audio_logs_dir / session_id
            timestamp_str = datetime.now().strftime('%H%M%S_%f')[:-3]  # –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
            audio_filename = f"analysis_{timestamp_str}.wav"
            sf.write(
                session_dir / audio_filename,
                audio_array,
                self.config['sample_rate']
            )
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            is_candidate = speaker_result.get('is_candidate', False)
            confidence = speaker_result.get('confidence', 0) * 100
            text = transcription_result.get('text', 'N/A')[:100]
            processing_time = transcription_result.get('processing_time', 0)
            
            status = "üü¢ –ö–ê–ù–î–ò–î–ê–¢" if is_candidate else "üî¥ –ù–ï –ö–ê–ù–î–ò–î–ê–¢"
            logger.info(f"üé§ {status} ({confidence:.1f}%) [{processing_time:.1f}—Å] - '{text}'")
            
            return {
                "success": True,
                "result": analysis_result
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—á–∏: {e}")
            return {"success": False, "error": str(e)}
    
    def identify_speaker(self, current_features: np.ndarray) -> Dict:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ (–∫–∞–Ω–¥–∏–¥–∞—Ç –∏–ª–∏ –Ω–µ—Ç) - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
        try:
            if not self.is_calibrated or self.candidate_voice_profile is None:
                return {"is_candidate": False, "confidence": 0.0, "error": "–ù–µ –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–æ"}
            
            if current_features is None or len(current_features) == 0:
                return {"is_candidate": False, "confidence": 0.0, "error": "–ù–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"}
            
            # –ü–æ–ª—É—á–∞–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
            mean_profile = np.array(self.candidate_voice_profile['mean_features'])
            scaler_mean = np.array(self.candidate_voice_profile['scaler_mean'])
            scaler_scale = np.array(self.candidate_voice_profile['scaler_scale'])
            
            if len(current_features) != len(mean_profile):
                return {"is_candidate": False, "confidence": 0.0, "error": "–ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"}
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—É—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–µ–º –∂–µ scaler'–æ–º
            normalized_current = (current_features - scaler_mean) / scaler_scale
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å (cosine similarity)
            try:
                cos_distance = cosine(normalized_current, mean_profile)
                if np.isnan(cos_distance):
                    cos_distance = 1.0  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ö–æ–∂–µ—Å—Ç—å (–æ—Ç 0 –¥–æ 1)
                similarity = 1.0 - cos_distance
                similarity = max(0.0, min(1.0, similarity))
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ "–≤–Ω—É—Ç—Ä–∏-–∫–ª–∞—Å—Å" —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
                avg_intra_distance = self.candidate_voice_profile.get('avg_intra_distance', 0.3)
                
                # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
                quality_score = self.candidate_voice_profile.get('quality_score', 0.8)
                adaptive_threshold = self.config['similarity_threshold'] * (0.8 + 0.2 * quality_score)
                
                # –£—á–∏—Ç—ã–≤–∞–µ–º "–≤–Ω—É—Ç—Ä–∏-–∫–ª–∞—Å—Å" –≤–∞—Ä–∏–∞—Ü–∏—é
                if cos_distance <= avg_intra_distance * 1.5:
                    # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π –≤–∞—Ä–∏–∞—Ü–∏–∏ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç
                    confidence_boost = 0.1
                else:
                    confidence_boost = 0.0
                
                final_similarity = similarity + confidence_boost
                is_candidate = final_similarity >= adaptive_threshold
                

                return {
                    "is_candidate": bool(is_candidate),
                    "confidence": float(final_similarity),
                    "raw_similarity": float(similarity),
                    "cosine_distance": float(cos_distance),
                    "threshold": float(adaptive_threshold),
                    "intra_class_distance": float(avg_intra_distance),
                    "method": "cosine_similarity_adaptive",
                    "quality_score": float(quality_score)
                }
                
            except Exception as calc_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏: {calc_error}")
                return {"is_candidate": False, "confidence": 0.0, "error": f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π: {calc_error}"}
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ: {e}")
            return {"is_candidate": False, "confidence": 0.0, "error": str(e)}
    
    async def get_session_logs(self, session_id: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ —Å–µ—Å—Å–∏–∏"""
        try:
            session_dir = self.audio_logs_dir / session_id
            
            if not session_dir.exists():
                return {"success": False, "error": "–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
            
            # –ß–∏—Ç–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å (–µ—Å–ª–∏ –µ—Å—Ç—å)
            voice_profile = None
            profile_file = session_dir / "voice_profile.json"
            if profile_file.exists():
                with open(profile_file, 'r', encoding='utf-8') as f:
                    voice_profile = json.load(f)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª—ã
            audio_files = list(session_dir.glob("*.wav"))
            calibration_files = [f for f in audio_files if "calibration" in f.name]
            analysis_files = [f for f in audio_files if "analysis" in f.name]
            
            return {
                "success": True,
                "session_id": session_id,
                "voice_profile": voice_profile,
                "calibration_files": [f.name for f in calibration_files],
                "analysis_files": [f.name for f in analysis_files],
                "total_audio_files": len(audio_files),
                "analysis_history": self.analysis_history[-20:],  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20
                "is_calibrated": self.is_calibrated,
                "total_samples": len(self.calibration_samples),
                "system_stats": self.get_system_stats()
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–≥–æ–≤: {e}")
            return {"success": False, "error": str(e)}
    
    def get_system_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
        return {
            "whisper_model": self.config['whisper_model'],
            "whisper_loaded": self._whisper_loaded,
            "is_calibrated": self.is_calibrated,
            "calibration_samples": len(self.calibration_samples),
            "analysis_history": len(self.analysis_history),
            "config": self.config,
            "voice_profile_quality": self.candidate_voice_profile.get('quality_score', 0.0) if self.candidate_voice_profile else 0.0,
            "ffmpeg_available": self.ffmpeg_available,
            "supported_methods": self._get_supported_methods()
        }
    
    def _get_supported_methods(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ"""
        methods = [
            "librosa (native)",
            "soundfile", 
            "raw PCM extraction"
        ]
        
        if self.ffmpeg_available:
            methods.extend([
                "pydub + ffmpeg",
                "ffmpeg direct conversion"
            ])
        
        methods.append("webm as ogg fallback")
        
        return methods
    
    def reset_system(self):
        """–°–±—Ä–æ—Å —Å–∏—Å—Ç–µ–º—ã (–æ—á–∏—Å—Ç–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏)"""
        logger.info("üîÑ –°–±—Ä–æ—Å —Å–∏—Å—Ç–µ–º—ã AudioProctorSystem")
        self.is_calibrated = False
        self.candidate_voice_profile = None
        self.calibration_samples = []
        self.analysis_history = []

# === –ì–õ–û–ë–ê–õ–¨–ù–´–ô –≠–ö–ó–ï–ú–ü–õ–Ø–† –° –ö–ï–®–ò–†–û–í–ê–ù–ò–ï–ú ===
_global_audio_proctor = None

async def get_audio_proctor(data_dir: Path) -> AudioProctorSystem:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ AudioProctorSystem (—Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏)"""
    global _global_audio_proctor
    
    if _global_audio_proctor is None:
        logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ AudioProctorSystem")
        _global_audio_proctor = AudioProctorSystem(data_dir)
        success = await _global_audio_proctor.initialize()
        
        if not success:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å AudioProctorSystem")
            _global_audio_proctor = None
            raise RuntimeError("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ —Å–∏—Å—Ç–µ–º—ã")
        
        logger.info("‚úÖ –ì–ª–æ–±–∞–ª—å–Ω—ã–π AudioProctorSystem –≥–æ—Ç–æ–≤")
    
    return _global_audio_proctor

# === –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ===

def audio_bytes_to_numpy(audio_bytes: bytes, sample_rate: int = 16000) -> np.ndarray:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è bytes –≤ numpy array"""
    try:
        audio_io = io.BytesIO(audio_bytes)
        audio, sr = librosa.load(audio_io, sr=sample_rate)
        return librosa.util.normalize(audio)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        return np.array([])

def base64_to_audio(base64_data: str, sample_rate: int = 16000) -> np.ndarray:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è base64 –≤ numpy array"""
    try:
        audio_bytes = base64.b64decode(base64_data)
        return audio_bytes_to_numpy(audio_bytes, sample_rate)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è base64: {e}")
        return np.array([])

# === –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –°–ò–°–¢–ï–ú–´ ===
if __name__ == "__main__":
    async def test_system():
        """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã"""
        from pathlib import Path
        
        print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AudioProctorSystem...")
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
        system = AudioProctorSystem(Path("test_data"))
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º (–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏)
        print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper –º–æ–¥–µ–ª—å...")
        if await system.initialize():
            print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {system.get_system_stats()}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞
            if system._whisper_loaded:
                print("‚ôªÔ∏è –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–π)...")
                start_time = datetime.now()
                await system.initialize()
                load_time = (datetime.now() - start_time).total_seconds()
                print(f"‚ö° –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞ {load_time:.2f} —Å–µ–∫ (–∫–µ—à —Ä–∞–±–æ—Ç–∞–µ—Ç!)")
            
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏")
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
    asyncio.run(test_system())