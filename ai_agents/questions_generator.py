"""
Questions Generator - –ò–ò –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
–°–æ–∑–¥–∞–µ—Ç 30-50 —É–º–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ –∫–∞–∂–¥—ã–π —Ç–µ–≥ –≤ 3 —É—Ä–æ–≤–Ω—è—Ö —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
"""

import json
import logging
import re
import uuid
from typing import Dict, List, Optional, Any
from pathlib import Path
from datetime import datetime

# –ò–ò
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)


class QuestionsGenerator:
    """–ò–ò –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤"""
    
    def __init__(self, openai_api_key: str, data_dir: Path):
        self.openai_api_key = openai_api_key
        self.data_dir = data_dir
        self.openai_client = None
        
        self._initialize_openai()
    
    def _initialize_openai(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞"""
        try:
            if self.openai_api_key:
                self.openai_client = AsyncOpenAI(api_key=self.openai_api_key)
                logger.info("‚úÖ Questions Generator: OpenAI –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            else:
                logger.warning("‚ö†Ô∏è Questions Generator: OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            logger.error(f"‚ùå Questions Generator: –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI: {e}")
    
    # === –ì–ï–ù–ï–†–ê–¶–ò–Ø –í–û–ü–†–û–°–û–í –î–õ–Ø –ü–†–û–§–ï–°–°–ò–ò ===
    
    async def generate_questions_for_profession(self, profession: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ç–µ–≥–æ–≤ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏"""
        try:
            tags = profession.get("tags", {})
            if not tags:
                return {
                    "success": False,
                    "error": "–£ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –Ω–µ—Ç —Ç–µ–≥–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤"
                }
            
            profession_context = {
                "bank_title": profession.get("bank_title", ""),
                "real_name": profession.get("real_name", ""),
                "specialization": profession.get("specialization", ""),
                "department": profession.get("department", "")
            }
            
            all_questions = []
            generation_stats = {
                "total_tags": len(tags),
                "successful_tags": 0,
                "failed_tags": 0,
                "total_questions": 0,
                "questions_by_difficulty": {"easy": 0, "medium": 0, "hard": 0}
            }
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–≥–∞
            for tag, weight in tags.items():
                logger.info(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç–µ–≥–∞: {tag} ({weight}%)")
                
                tag_questions = await self._generate_questions_for_tag(
                    tag, weight, profession_context
                )
                
                if tag_questions.get("success"):
                    all_questions.extend(tag_questions["questions"])
                    generation_stats["successful_tags"] += 1
                    generation_stats["total_questions"] += len(tag_questions["questions"])
                    
                    # –ü–æ–¥—Å—á–µ—Ç –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
                    for question in tag_questions["questions"]:
                        difficulty = question.get("difficulty", "medium")
                        generation_stats["questions_by_difficulty"][difficulty] += 1
                else:
                    generation_stats["failed_tags"] += 1
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è —Ç–µ–≥–∞: {tag}")
            
            return {
                "success": True,
                "questions": all_questions,
                "stats": generation_stats,
                "generated_at": datetime.now().isoformat() + "Z"
            }
            
        except Exception as e:
            logger.error(f"‚ùå Questions Generator: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _generate_questions_for_tag(self, tag: str, weight: int, profession_context: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è 30-50 –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–≥–∞ –≤ 3 —É—Ä–æ–≤–Ω—è—Ö —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        try:
            if not self.openai_client:
                return await self._manual_generate_questions_for_tag(tag, weight, profession_context)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Å–∞ —Ç–µ–≥–∞
            questions_distribution = self._calculate_questions_distribution(weight)
            
            all_questions = []
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—Ä–æ–≤–Ω—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            for difficulty, count in questions_distribution.items():
                difficulty_questions = await self._generate_difficulty_level_questions(
                    tag, difficulty, count, profession_context
                )
                
                if difficulty_questions:
                    all_questions.extend(difficulty_questions)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫ –≤–æ–ø—Ä–æ—Å–∞–º
            for question in all_questions:
                question["tag"] = tag
                question["tag_weight"] = weight
                question["profession_context"] = profession_context["real_name"]
                question["id"] = str(uuid.uuid4())
                question["generated_at"] = datetime.now().isoformat() + "Z"
            
            return {
                "success": True,
                "tag": tag,
                "questions": all_questions,
                "total_questions": len(all_questions),
                "distribution": questions_distribution
            }
            
        except Exception as e:
            logger.error(f"‚ùå Questions Generator: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Ç–µ–≥–∞ {tag}: {e}")
            return {
                "success": False,
                "tag": tag,
                "error": str(e)
            }
    
    def _calculate_questions_distribution(self, weight: int) -> Dict[str, int]:
        """–†–∞—Å—á–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Å–∞ —Ç–µ–≥–∞"""
        # –ë–∞–∑–æ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: 30-50 –≤–æ–ø—Ä–æ—Å–æ–≤
        if weight >= 85:
            # –ö—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–Ω—ã–π —Ç–µ–≥ - –º–∞–∫—Å–∏–º—É–º –≤–æ–ø—Ä–æ—Å–æ–≤
            return {"easy": 5, "medium": 7, "hard": 5}  # 50 –≤–æ–ø—Ä–æ—Å–æ–≤
        elif weight >= 70:
            # –í–∞–∂–Ω—ã–π —Ç–µ–≥ - –º–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤
            return {"easy": 4, "medium": 5, "hard": 4}  # 40 –≤–æ–ø—Ä–æ—Å–æ–≤
        elif weight >= 55:
            # –°—Ä–µ–¥–Ω–∏–π —Ç–µ–≥ - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            return {"easy": 3, "medium": 4, "hard": 3}  # 32 –≤–æ–ø—Ä–æ—Å–∞
        else:
            # –ù–∏–∑–∫–∏–π –≤–µ—Å - –º–∏–Ω–∏–º—É–º –≤–æ–ø—Ä–æ—Å–æ–≤
            return {"easy": 3, "medium": 4, "hard": 2}   # 25 –≤–æ–ø—Ä–æ—Å–æ–≤
    
    async def _generate_difficulty_level_questions(self, tag: str, difficulty: str, count: int, profession_context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        try:
            prompt = self._create_questions_prompt(tag, difficulty, count, profession_context)
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": self._get_system_prompt(difficulty)},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4,  # –ù–µ–º–Ω–æ–≥–æ —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–∞ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤
                max_tokens=4000
            )
            
            response_text = response.choices[0].message.content.strip()
            questions = self._parse_questions_response(response_text, difficulty)
            
            logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(questions)} –≤–æ–ø—Ä–æ—Å–æ–≤ —É—Ä–æ–≤–Ω—è {difficulty} –¥–ª—è —Ç–µ–≥–∞ {tag}")
            return questions
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ {difficulty} –¥–ª—è {tag}: {e}")
            return []
    
    def _create_questions_prompt(self, tag: str, difficulty: str, count: int, profession_context: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤"""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏
        profession = profession_context.get('real_name', '')
        specialization = profession_context.get('specialization', '')
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä
        example = self._get_example_for_context(tag, profession, specialization, difficulty)
        
        return f"""
    –°–æ–∑–¥–∞–π {count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ —É—Ä–æ–≤–Ω—è {difficulty} –ø–æ —Ç–µ–≥—É "{tag}" –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ "{profession}" (—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {specialization}).

    –ü–†–ò–ú–ï–† –°–¢–†–£–ö–¢–£–†–´:
    {example['question']}
    A) {example['options'][0]} ‚úì
    B) {example['options'][1]}
    C) {example['options'][2]}
    D) {example['options'][3]}

    –ü–†–ê–í–ò–õ–ê:
    1. –í—Å–µ –≤–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –†–ê–ó–ù–´–ï (–Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è)
    2. –î–∏—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –¢–û–õ–¨–ö–û –∏–∑ –æ–±–ª–∞—Å—Ç–∏ "{tag}" –∏–ª–∏ —Å–º–µ–∂–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π
    3. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∏–∑ –¥—Ä—É–≥–∏—Ö –æ–±–ª–∞—Å—Ç–µ–π
    4. –î–∏—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –ù–ï –¥–æ–ª–∂–Ω—ã –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è –º–µ–∂–¥—É –≤–æ–ø—Ä–æ—Å–∞–º–∏
    5. –í—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω—ã –≤—ã–≥–ª—è–¥–µ—Ç—å –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–æ (–Ω–µ–ª—å–∑—è —É–≥–∞–¥–∞—Ç—å –º–µ—Ç–æ–¥–æ–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è)

    –§–û–†–ú–ê–¢ JSON:
    [
        {{
            "question": "–í–æ–ø—Ä–æ—Å –æ {tag} –¥–ª—è {profession}?",
            "options": ["–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç", "–î–∏—Å—Ç—Ä–∞–∫—Ç–æ—Ä 1", "–î–∏—Å—Ç—Ä–∞–∫—Ç–æ—Ä 2", "–î–∏—Å—Ç—Ä–∞–∫—Ç–æ—Ä 3"],
            "correct_answer": "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç",
            "explanation": "–ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ",
            "difficulty": "{difficulty}",
            "category": "–ö–∞—Ç–µ–≥–æ—Ä–∏—è –≤–æ–ø—Ä–æ—Å–∞"
        }}
    ]
    """

    def _get_example_for_context(self, tag: str, profession: str, specialization: str, difficulty: str) -> dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        
        examples = {
            # Python –ø—Ä–∏–º–µ—Ä—ã
            ("Python", "Data Scientist", "Machine Learning", "easy"): {
                "question": "–ö–∞–∫–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Python –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–∞—Å—Å–∏–≤–∞–º–∏ –∏ –º–∞—Ç—Ä–∏—Ü–∞–º–∏?",
                "options": ["NumPy", "requests", "datetime", "os"]
            },
            ("Python", "Data Scientist", "Machine Learning", "medium"): {
                "question": "–ö–∞–∫–æ–π –º–µ—Ç–æ–¥ sklearn –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ train/test?",
                "options": ["train_test_split()", "split_data()", "divide_dataset()", "separate_data()"]
            },
            ("Python", "Data Scientist", "Computer Vision", "medium"): {
                "question": "–ö–∞–∫–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ Python?",
                "options": ["OpenCV", "requests", "json", "datetime"]
            },
            ("Python", "Software Developer", "Backend Development", "easy"): {
                "question": "–ö–∞–∫–æ–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è REST API –≤ Python?",
                "options": ["FastAPI", "pandas", "numpy", "matplotlib"]
            },
            
            # Machine Learning –ø—Ä–∏–º–µ—Ä—ã
            ("Machine Learning", "Data Scientist", "Machine Learning", "easy"): {
                "question": "–ö–∞–∫–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º –ª—É—á—à–µ –≤—Å–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –ª–∏–Ω–µ–π–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–º—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏?",
                "options": ["–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è", "K-means", "PCA", "DBSCAN"]
            },
            ("Machine Learning", "Data Scientist", "Machine Learning", "medium"): {
                "question": "–ö–∞–∫–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏?",
                "options": ["F1-score", "MSE", "MAE", "R¬≤"]
            },
            ("Machine Learning", "Data Scientist", "Computer Vision", "medium"): {
                "question": "–ö–∞–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –ª—É—á—à–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π?",
                "options": ["CNN", "RNN", "LSTM", "GRU"]
            },
            
            # SQL –ø—Ä–∏–º–µ—Ä—ã
            ("SQL", "Data Scientist", "Machine Learning", "easy"): {
                "question": "–ö–∞–∫–∞—è –∫–æ–º–∞–Ω–¥–∞ SQL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤—ã–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–∞–±–ª–∏—Ü—ã?",
                "options": ["SELECT", "GET", "FETCH", "RETRIEVE"]
            },
            ("SQL", "Data Analyst", "Business Intelligence", "medium"): {
                "question": "–ö–∞–∫–∞—è –∫–æ–º–∞–Ω–¥–∞ SQL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü –ø–æ –∫–ª—é—á—É?",
                "options": ["JOIN", "MERGE", "COMBINE", "UNITE"]
            },
            
            # Deep Learning –ø—Ä–∏–º–µ—Ä—ã
            ("Deep Learning", "Data Scientist", "Computer Vision", "medium"): {
                "question": "–ö–∞–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —á–∞—â–µ –≤—Å–µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π?",
                "options": ["ReLU", "Sigmoid", "Tanh", "Linear"]
            },
            ("Deep Learning", "Data Scientist", "Machine Learning", "hard"): {
                "question": "–ö–∞–∫–æ–π –º–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö?",
                "options": ["Dropout", "Normalization", "Standardization", "Aggregation"]
            },
            
            # Computer Vision –ø—Ä–∏–º–µ—Ä—ã
            ("Computer Vision", "Data Scientist", "Computer Vision", "easy"): {
                "question": "–ö–∞–∫–æ–π —Ñ–∏–ª—å—Ç—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ä–∞–∑–º—ã—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è?",
                "options": ["–ì–∞—É—Å—Å–æ–≤ —Ñ–∏–ª—å—Ç—Ä", "–ú–µ–¥–∏–∞–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä", "–°–æ–±–µ–ª —Ñ–∏–ª—å—Ç—Ä", "–õ–∞–ø–ª–∞—Å–∏–∞–Ω"]
            },
            ("Computer Vision", "Data Scientist", "Computer Vision", "medium"): {
                "question": "–ö–∞–∫–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥—Ä–∞–Ω–∏—Ü –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏?",
                "options": ["Canny", "SIFT", "SURF", "ORB"]
            },
            
            # Data Analysis –ø—Ä–∏–º–µ—Ä—ã
            ("Data Analysis", "Data Scientist", "Machine Learning", "easy"): {
                "question": "–ö–∞–∫–∞—è –º–µ—Ä–∞ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ —É—Å—Ç–æ–π—á–∏–≤–∞ –∫ –≤—ã–±—Ä–æ—Å–∞–º?",
                "options": ["–ú–µ–¥–∏–∞–Ω–∞", "–°—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ", "–†–∞–∑–º–∞—Ö", "–î–∏—Å–ø–µ—Ä—Å–∏—è"]
            },
            ("Data Analysis", "Data Analyst", "Business Intelligence", "medium"): {
                "question": "–ö–∞–∫–æ–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–∑–º–µ—Ä—è–µ—Ç –ª–∏–Ω–µ–π–Ω—É—é —Å–≤—è–∑—å –º–µ–∂–¥—É –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏?",
                "options": ["–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞", "–î–∏—Å–ø–µ—Ä—Å–∏—è", "–°—Ä–µ–¥–Ω–µ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ", "–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏"]
            },
            
            # Statistics –ø—Ä–∏–º–µ—Ä—ã
            ("Statistics", "Data Scientist", "Machine Learning", "medium"): {
                "question": "–ö–∞–∫–æ–π —Ç–µ—Å—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è?",
                "options": ["–¢–µ—Å—Ç –®–∞–ø–∏—Ä–æ-–£–∏–ª–∫–∞", "t-—Ç–µ—Å—Ç", "–¢–µ—Å—Ç –§–∏—à–µ—Ä–∞", "–¢–µ—Å—Ç –õ–µ–≤–µ–Ω–∞"]
            },
            
            # TensorFlow –ø—Ä–∏–º–µ—Ä—ã
            ("TensorFlow", "Data Scientist", "Deep Learning", "medium"): {
                "question": "–ö–∞–∫–æ–π –∫–ª–∞—Å—Å –≤ TensorFlow –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è?",
                "options": ["Dense", "Conv2D", "LSTM", "Embedding"]
            },
            
            # OpenCV –ø—Ä–∏–º–µ—Ä—ã
            ("OpenCV", "Data Scientist", "Computer Vision", "easy"): {
                "question": "–ö–∞–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è OpenCV –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —á—Ç–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è?",
                "options": ["cv2.imread()", "cv2.load()", "cv2.open()", "cv2.get()"]
            },
            
            # Git –ø—Ä–∏–º–µ—Ä—ã (–¥–ª—è –ª—é–±—ã—Ö IT –ø—Ä–æ—Ñ–µ—Å—Å–∏–π)
            ("Git", "Software Developer", "Backend Development", "easy"): {
                "question": "–ö–∞–∫–∞—è –∫–æ–º–∞–Ω–¥–∞ Git –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–º–º–∏—Ç–∞?",
                "options": ["git commit", "git save", "git push", "git add"]
            },
            
            # Docker –ø—Ä–∏–º–µ—Ä—ã
            ("Docker", "Software Developer", "DevOps", "medium"): {
                "question": "–ö–∞–∫–∞—è –∫–æ–º–∞–Ω–¥–∞ Docker –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞?",
                "options": ["docker run", "docker start", "docker launch", "docker execute"]
            }
        }
        
        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        key = (tag, profession, specialization, difficulty)
        if key in examples:
            return examples[key]
        
        # –ò—â–µ–º –±–µ–∑ —É—á–µ—Ç–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        for (t, p, s, d), example in examples.items():
            if t == tag and p == profession and s == specialization:
                return example
        
        # –ò—â–µ–º –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        for (t, p, s, d), example in examples.items():
            if t == tag and p == profession:
                return example
        
        # –ò—â–µ–º —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–≥—É
        for (t, p, s, d), example in examples.items():
            if t == tag:
                return example
        
        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä
        return {
            "question": f"–í–æ–ø—Ä–æ—Å –æ {tag} –¥–ª—è {profession}?",
            "options": ["–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç", "–î–∏—Å—Ç—Ä–∞–∫—Ç–æ—Ä 1", "–î–∏—Å—Ç—Ä–∞–∫—Ç–æ—Ä 2", "–î–∏—Å—Ç—Ä–∞–∫—Ç–æ—Ä 3"]
        }
    
    def _get_system_prompt(self, difficulty: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        base_prompt = "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –∏–Ω—Ç–µ—Ä–≤—å—é –≤ –±–∞–Ω–∫–µ. –°–æ–∑–¥–∞–µ—à—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–≤—ã–∫–æ–≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤."
        
        if difficulty == "easy":
            return base_prompt + " –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏—è—Ö –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è—Ö."
        elif difficulty == "medium":
            return base_prompt + " –°–æ–∑–¥–∞–≤–∞–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç–µ."
        else:  # hard
            return base_prompt + " –ì–µ–Ω–µ—Ä–∏—Ä—É–π —Å–ª–æ–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –≤–∫–ª—é—á–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É."
    
    def _parse_questions_response(self, response: str, difficulty: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –ò–ò —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏"""
        try:
            # –ò—â–µ–º JSON –º–∞—Å—Å–∏–≤ –≤ –æ—Ç–≤–µ—Ç–µ
            json_match = re.search(r'\[.*\]', response, re.DOTALL)
            if json_match:
                questions_data = json.loads(json_match.group())
                
                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –∫–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å
                validated_questions = []
                for question in questions_data:
                    if self._validate_question(question):
                        question["difficulty"] = difficulty
                        validated_questions.append(question)
                
                return validated_questions
            else:
                logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω JSON –º–∞—Å—Å–∏–≤ –≤ –æ—Ç–≤–µ—Ç–µ –ò–ò")
                return []
                
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            return []
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
            return []
    
    def _validate_question(self, question: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤–æ–ø—Ä–æ—Å–∞"""
        required_fields = ["question", "options", "correct_answer", "explanation"]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        for field in required_fields:
            if field not in question:
                logger.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ {field} –≤ –≤–æ–ø—Ä–æ—Å–µ")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞
        if not isinstance(question["options"], list) or len(question["options"]) != 4:
            logger.warning("‚ö†Ô∏è –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –µ—Å—Ç—å —Å—Ä–µ–¥–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        if question["correct_answer"] not in question["options"]:
            logger.warning("‚ö†Ô∏è –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω —Å—Ä–µ–¥–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –≤–æ–ø—Ä–æ—Å–∞
        if len(question["question"].strip()) < 10:
            logger.warning("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –≤–æ–ø—Ä–æ—Å")
            return False
        
        return True
    
    # === –†–£–ß–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø (FALLBACK) ===
    
    async def _manual_generate_questions_for_tag(self, tag: str, weight: int, profession_context: Dict[str, Any]) -> Dict[str, Any]:
        """–†—É—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∫–æ–≥–¥–∞ –ò–ò –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        try:
            # –ë–∞–∑–æ–≤—ã–µ —à–∞–±–ª–æ–Ω—ã –≤–æ–ø—Ä–æ—Å–æ–≤
            manual_questions = self._create_manual_questions_templates(tag, weight)
            
            return {
                "success": True,
                "tag": tag,
                "questions": manual_questions,
                "total_questions": len(manual_questions),
                "source": "manual_fallback"
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä—É—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è {tag}: {e}")
            return {"success": False, "tag": tag, "error": str(e)}
    
    def _create_manual_questions_templates(self, tag: str, weight: int) -> List[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤ –≤–æ–ø—Ä–æ—Å–æ–≤"""
        questions = []
        
        # –ë–∞–∑–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ª—é–±–æ–≥–æ —Ç–µ–≥–∞
        base_questions = [
            {
                "question": f"–ß—Ç–æ —Ç–∞–∫–æ–µ {tag} –∏ –¥–ª—è —á–µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è?",
                "options": [
                    "–Ø–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è",
                    "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏", 
                    "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞",
                    "–ó–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"
                ],
                "correct_answer": "–ó–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞",
                "explanation": f"{tag} –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±–ª–∞—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è",
                "difficulty": "easy",
                "category": "basic_concepts"
            },
            {
                "question": f"–ö–∞–∫–æ–π —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞–Ω–∏—è {tag} —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã?",
                "options": [
                    "–ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å",
                    "–°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å",
                    "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å", 
                    f"–ó–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ {tag}"
                ],
                "correct_answer": f"–ó–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ {tag}",
                "explanation": f"–£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞–Ω–∏—è {tag} –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –µ–≥–æ –≤–∞–∂–Ω–æ—Å—Ç—å—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏",
                "difficulty": "medium",
                "category": "skill_level"
            }
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        for question in base_questions:
            question["tag"] = tag
            question["tag_weight"] = weight
            question["id"] = str(uuid.uuid4())
            question["generated_at"] = datetime.now().isoformat() + "Z"
            question["source"] = "manual_template"
        
        return base_questions
    
    # === –ê–ù–ê–õ–ò–ó –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ù–´–• –í–û–ü–†–û–°–û–í ===
    
    def analyze_generated_questions(self, questions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤"""
        try:
            if not questions:
                return {"total_questions": 0, "analysis": "–ù–µ—Ç –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}
            
            analysis = {
                "total_questions": len(questions),
                "questions_by_difficulty": self._analyze_difficulty_distribution(questions),
                "questions_by_tag": self._analyze_tag_distribution(questions),
                "questions_by_category": self._analyze_category_distribution(questions),
                "quality_metrics": self._analyze_quality_metrics(questions),
                "recommendations": self._generate_questions_recommendations(questions)
            }
            
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
            return {"error": str(e)}
    
    def _analyze_difficulty_distribution(self, questions: List[Dict[str, Any]]) -> Dict[str, int]:
        """–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        distribution = {"easy": 0, "medium": 0, "hard": 0}
        
        for question in questions:
            difficulty = question.get("difficulty", "medium")
            if difficulty in distribution:
                distribution[difficulty] += 1
        
        return distribution
    
    def _analyze_tag_distribution(self, questions: List[Dict[str, Any]]) -> Dict[str, int]:
        """–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —Ç–µ–≥–∞–º"""
        distribution = {}
        
        for question in questions:
            tag = question.get("tag", "unknown")
            distribution[tag] = distribution.get(tag, 0) + 1
        
        return distribution
    
    def _analyze_category_distribution(self, questions: List[Dict[str, Any]]) -> Dict[str, int]:
        """–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        distribution = {}
        
        for question in questions:
            category = question.get("category", "general")
            distribution[category] = distribution.get(category, 0) + 1
        
        return distribution
    
    def _analyze_quality_metrics(self, questions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
        metrics = {
            "avg_question_length": 0,
            "avg_explanation_length": 0,
            "questions_with_categories": 0,
            "unique_questions": 0
        }
        
        question_texts = set()
        total_question_length = 0
        total_explanation_length = 0
        
        for question in questions:
            # –î–ª–∏–Ω–∞ –≤–æ–ø—Ä–æ—Å–æ–≤
            question_text = question.get("question", "")
            total_question_length += len(question_text)
            
            # –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å
            question_texts.add(question_text.lower())
            
            # –î–ª–∏–Ω–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
            explanation = question.get("explanation", "")
            total_explanation_length += len(explanation)
            
            # –ù–∞–ª–∏—á–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            if question.get("category"):
                metrics["questions_with_categories"] += 1
        
        if questions:
            metrics["avg_question_length"] = total_question_length / len(questions)
            metrics["avg_explanation_length"] = total_explanation_length / len(questions)
            metrics["unique_questions"] = len(question_texts)
            metrics["uniqueness_percentage"] = (len(question_texts) / len(questions)) * 100
        
        return metrics
    
    def _generate_questions_recommendations(self, questions: List[Dict[str, Any]]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –≤–æ–ø—Ä–æ—Å–æ–≤"""
        recommendations = []
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        difficulty_dist = self._analyze_difficulty_distribution(questions)
        total = sum(difficulty_dist.values())
        
        if total > 0:
            easy_pct = (difficulty_dist["easy"] / total) * 100
            medium_pct = (difficulty_dist["medium"] / total) * 100
            hard_pct = (difficulty_dist["hard"] / total) * 100
            
            if easy_pct < 20:
                recommendations.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤")
            elif easy_pct > 50:
                recommendations.append("–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤")
            
            if hard_pct < 15:
                recommendations.append("–î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏")
            elif hard_pct > 40:
                recommendations.append("–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        quality_metrics = self._analyze_quality_metrics(questions)
        
        if quality_metrics.get("uniqueness_percentage", 100) < 90:
            recommendations.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –≤–æ–ø—Ä–æ—Å—ã")
        
        if quality_metrics.get("avg_question_length", 0) < 20:
            recommendations.append("–í–æ–ø—Ä–æ—Å—ã —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ, –¥–æ–±–∞–≤—å—Ç–µ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏")
        
        if quality_metrics.get("questions_with_categories", 0) < len(questions) * 0.8:
            recommendations.append("–î–æ–±–∞–≤—å—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        return recommendations

# –≠–∫—Å–ø–æ—Ä—Ç –∫–ª–∞—Å—Å–∞
__all__ = ['QuestionsGenerator']