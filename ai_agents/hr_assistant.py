"""
HR Assistant - –ò–ò –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤
–ü–æ–º–æ–≥–∞–µ—Ç –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–π, –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–æ–≤, –ø—Ä–æ–≤–µ—Ä–∫–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
"""

import json
import logging
import re
from typing import Dict, List, Optional, Any
from pathlib import Path
from datetime import datetime

# –ò–ò
from openai import AsyncOpenAI
import httpx

# –†–∞–±–æ—Ç–∞ —Å —Ñ–∞–π–ª–∞–º–∏
import PyPDF2
import docx

logger = logging.getLogger(__name__)


class HRAssistant:
    """–ò–ò –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤"""
    
    def __init__(self, openai_api_key: str, data_dir: Path):
        self.openai_api_key = openai_api_key
        self.data_dir = data_dir
        self.openai_client = None
        self.profession_data = {}
        
        self._initialize_openai()
        self._load_profession_data()
    
    def _initialize_openai(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞"""
        try:
            if self.openai_api_key:
                self.openai_client = AsyncOpenAI(api_key=self.openai_api_key)
                logger.info("‚úÖ HR Assistant: OpenAI –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            else:
                logger.warning("‚ö†Ô∏è HR Assistant: OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI: {e}")
    
    def _load_profession_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ—Ñ–µ—Å—Å–∏—è—Ö"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
            records_file = self.data_dir / "profession_records.json"
            if records_file.exists():
                with open(records_file, 'r', encoding='utf-8') as f:
                    self.profession_data = json.load(f)
            else:
                self.profession_data = {"profession_records": []}
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏
            self._load_reference_files()
            
            logger.info(f"‚úÖ HR Assistant: –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.profession_data.get('profession_records', []))} –∑–∞–ø–∏—Å–µ–π")
            
        except Exception as e:
            logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            self.profession_data = {"profession_records": []}
    
    def _load_reference_files(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        reference_files = ['departments.json', 'professions.json', 'specializations.json', 'bank_titles.json']
        
        for filename in reference_files:
            try:
                file_path = self.data_dir / filename
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        key = filename.replace('.json', '')
                        self.profession_data[key] = json.load(f)
            except Exception as e:
                logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filename}: {e}")
    
    # === –ê–ù–ê–õ–ò–ó –§–ê–ô–õ–û–í ===
    
    async def analyze_file(self, file_path: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
            text_content = await self._extract_text_from_file(file_path)
            
            if not text_content or len(text_content.strip()) < 50:
                return {
                    "success": False,
                    "error": "–§–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞",
                    "suggestions": []
                }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –ò–ò
            analysis = await self._ai_analyze_file_content(text_content)
            
            return {
                "success": True,
                "content_preview": text_content[:300] + "..." if len(text_content) > 300 else text_content,
                "analysis": analysis,
                "suggestions": self._generate_form_suggestions(analysis)
            }
            
        except Exception as e:
            logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞: {e}")
            return {
                "success": False,
                "error": str(e),
                "suggestions": []
            }
    
    async def _extract_text_from_file(self, file_path: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
        file_path = Path(file_path)
        
        if file_path.suffix.lower() == '.pdf':
            return self._extract_pdf_text(file_path)
        elif file_path.suffix.lower() in ['.docx', '.doc']:
            return self._extract_docx_text(file_path)
        elif file_path.suffix.lower() == '.txt':
            return self._extract_txt_text(file_path)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_path.suffix}")
    
    def _extract_pdf_text(self, file_path: Path) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"""
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                return text.strip()
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF: {e}")
    
    def _extract_docx_text(self, file_path: Path) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOCX"""
        try:
            doc = docx.Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text.strip()
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX: {e}")
    
    def _extract_txt_text(self, file_path: Path) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ TXT"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read().strip()
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è TXT: {e}")
    
    async def _ai_analyze_file_content(self, content: str) -> Dict[str, Any]:
        """–ò–ò –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞"""
        if not self.openai_client:
            return self._manual_file_analysis(content)
        
        try:
            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏/–ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –¥–ª—è –±–∞–Ω–∫–∞ Halyk Bank.
            
            –¢–ï–ö–°–¢: {content}
            
            –ò–∑–≤–ª–µ–∫–∏ –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≤–µ—Ä–Ω–∏ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {{
                "position_title": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞",
                "department_suggestion": "–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç",
                "real_profession": "—Ä–µ–∞–ª—å–Ω–∞—è –ø—Ä–æ—Ñ–µ—Å—Å–∏—è",
                "specialization": "—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å",
                "experience_level": "Junior/Middle/Senior",
                "key_requirements": ["–æ—Å–Ω–æ–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è"],
                "summary": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏"
            }}
            
            –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –º–∞–ª–æ, —É–∫–∞–∂–∏ null –¥–ª—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª–µ–π.
            –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON!
            """
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "–¢—ã HR —ç–∫—Å–ø–µ—Ä—Ç –±–∞–Ω–∫–∞. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –≤–∞–∫–∞–Ω—Å–∏–∏ —Ç–æ—á–Ω–æ –∏ –∫—Ä–∞—Ç–∫–æ."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=800
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # –ü–∞—Ä—Å–∏–º JSON
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞"}
                
        except Exception as e:
            logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ –ò–ò –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return self._manual_file_analysis(content)
    
    def _manual_file_analysis(self, content: str) -> Dict[str, Any]:
        """–†—É—á–Ω–æ–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ (fallback)"""
        content_lower = content.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        department_keywords = {
            "IT Department": ["—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç", "it", "–¥–∞–Ω–Ω—ã—Ö", "–∞–Ω–∞–ª–∏—Ç–∏–∫", "sql", "python"],
            "HR Department": ["hr", "–ø–µ—Ä—Å–æ–Ω–∞–ª", "–ø–æ–¥–±–æ—Ä", "—Ä–µ–∫—Ä—É—Ç–µ—Ä", "–∫–∞–¥—Ä—ã"],
            "Risk Department": ["—Ä–∏—Å–∫", "compliance", "–∫–æ–Ω—Ç—Ä–æ–ª—å", "–∞—É–¥–∏—Ç"],
            "Analytics Department": ["–∞–Ω–∞–ª–∏—Ç–∏–∫", "–¥–∞–Ω–Ω—ã—Ö", "–æ—Ç—á–µ—Ç", "bi", "dashboard"]
        }
        
        suggested_dept = "IT Department"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        for dept, keywords in department_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                suggested_dept = dept
                break
        
        return {
            "position_title": "–ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ —Ñ–∞–π–ª–∞",
            "department_suggestion": suggested_dept,
            "real_profession": None,
            "specialization": None,
            "experience_level": "Middle",
            "key_requirements": [],
            "summary": f"–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤"
        }
    
    def _generate_form_suggestions(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ–æ—Ä–º—ã"""
        suggestions = {}
        
        if analysis.get("department_suggestion"):
            suggestions["department"] = analysis["department_suggestion"]
        
        if analysis.get("real_profession"):
            suggestions["real_name"] = analysis["real_profession"]
        
        if analysis.get("specialization"):
            suggestions["specialization"] = analysis["specialization"]
        
        if analysis.get("position_title"):
            suggestions["bank_title"] = analysis["position_title"]
        
        return suggestions
    
    # === –ê–ù–ê–õ–ò–ó –§–û–†–ú–´ –í –†–ï–ê–õ–¨–ù–û–ú –í–†–ï–ú–ï–ù–ò ===
    
    async def analyze_form_data(self, form_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            duplicates = self._check_duplicates(form_data)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å
            logic_analysis = await self._analyze_form_logic(form_data)
            
            # –í–µ–±-–ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            web_info = await self._web_research(form_data)
            
            return {
                "duplicates": duplicates,
                "logic_analysis": logic_analysis,
                "web_info": web_info,
                "overall_score": self._calculate_form_score(duplicates, logic_analysis),
                "recommendations": self._generate_recommendations(duplicates, logic_analysis, web_info)
            }
            
        except Exception as e:
            logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ä–º—ã: {e}")
            return {
                "error": str(e),
                "recommendations": []
            }
    
    def _check_duplicates(self, form_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –±–∞–∑–µ"""
        duplicates = []
        
        try:
            existing_records = self.profession_data.get("profession_records", [])
            
            bank_title = form_data.get("bank_title", "").lower()
            real_name = form_data.get("real_name", "").lower()
            
            for record in existing_records:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ—É—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
                if record.get("status") not in ["approved_by_head", "questions_generated", "active"]:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –±–∞–Ω–∫–æ–≤—Å–∫–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è
                if record.get("bank_title", "").lower() == bank_title and bank_title:
                    duplicates.append({
                        "type": "exact_bank_title",
                        "existing": record,
                        "similarity": 1.0,
                        "message": "–ë–∞–Ω–∫–æ–≤—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
                    })
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ö–æ–∂–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                similarity = self._calculate_text_similarity(bank_title, record.get("bank_title", "").lower())
                if similarity > 0.8 and bank_title:
                    duplicates.append({
                        "type": "similar_bank_title",
                        "existing": record,
                        "similarity": similarity,
                        "message": f"–ü–æ—Ö–æ–∂–µ–µ –±–∞–Ω–∫–æ–≤—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ ({similarity:.0%} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)"
                    })
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ + —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
                if (record.get("real_name", "").lower() == real_name and 
                    record.get("specialization", "").lower() == form_data.get("specialization", "").lower() and
                    real_name):
                    duplicates.append({
                        "type": "exact_profession_spec",
                        "existing": record,
                        "similarity": 1.0,
                        "message": "–ü—Ä–æ—Ñ–µ—Å—Å–∏—è —Å —Ç–∞–∫–æ–π –∂–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
                    })
            
            return duplicates
            
        except Exception as e:
            logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")
            return []
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """–ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤"""
        if not text1 or not text2:
            return 0.0
        
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union)
    
    async def _analyze_form_logic(self, form_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ª–æ–≥–∏—á–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º—ã"""
        if not self.openai_client:
            return {"score": 0.8, "issues": [], "suggestions": []}
        
        try:
            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –¥–ª—è –±–∞–Ω–∫–∞:
            
            –î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç: {form_data.get('department', '–ù–µ —É–∫–∞–∑–∞–Ω')}
            –†–µ–∞–ª—å–Ω–∞—è –ø—Ä–æ—Ñ–µ—Å—Å–∏—è: {form_data.get('real_name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
            –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {form_data.get('specialization', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
            –ë–∞–Ω–∫–æ–≤—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: {form_data.get('bank_title', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
            
            –û—Ü–µ–Ω–∏ –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å (0.0-1.0) –∏ –Ω–∞–π–¥–∏ –ø—Ä–æ–±–ª–µ–º—ã. –û—Ç–≤–µ—Ç—å –≤ JSON:
            {{
                "score": 0.8,
                "issues": ["–ø—Ä–æ–±–ª–µ–º–∞1", "–ø—Ä–æ–±–ª–µ–º–∞2"],
                "suggestions": ["–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ1", "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ2"]
            }}
            
            –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON!
            """
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "–¢—ã HR —ç–∫—Å–ø–µ—Ä—Ç. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–π –∫—Ä–∞—Ç–∫–æ."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=400
            )
            
            response_text = response.choices[0].message.content.strip()
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            
            if json_match:
                return json.loads(json_match.group())
            else:
                return {"score": 0.8, "issues": [], "suggestions": []}
                
        except Exception as e:
            logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–∏–∫–∏: {e}")
            return {"score": 0.8, "issues": [], "suggestions": []}
    
    async def _web_research(self, form_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""
        try:
            profession_name = form_data.get("real_name", "")
            if not profession_name:
                return {"found": False, "info": "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ"}
            
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π –≤–µ–±-–ø–æ–∏—Å–∫
            # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
            return {
                "found": True,
                "info": f"–ù–∞–π–¥–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ '{profession_name}'",
                "sources": ["hh.ru", "linkedin.com"],
                "summary": "–ü–æ–ø—É–ª—è—Ä–Ω–∞—è –ø—Ä–æ—Ñ–µ—Å—Å–∏—è –≤ –±–∞–Ω–∫–æ–≤—Å–∫–æ–π —Å—Ñ–µ—Ä–µ"
            }
            
        except Exception as e:
            logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ –≤–µ–±-–ø–æ–∏—Å–∫–∞: {e}")
            return {"found": False, "info": "–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞"}
    
    def _calculate_form_score(self, duplicates: List[Dict], logic_analysis: Dict) -> float:
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏ —Ñ–æ—Ä–º—ã"""
        score = 1.0
        
        # –°–Ω–∏–∂–∞–µ–º –æ—Ü–µ–Ω–∫—É –∑–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
        for duplicate in duplicates:
            if duplicate["type"].startswith("exact_"):
                score -= 0.4
            elif duplicate["type"].startswith("similar_"):
                score -= 0.2
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º –ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        logic_score = logic_analysis.get("score", 0.8)
        score = (score + logic_score) / 2
        
        return max(0.0, min(1.0, score))
    
    def _generate_recommendations(self, duplicates: List[Dict], logic_analysis: Dict, web_info: Dict) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥—É–±–ª–∏–∫–∞—Ç–∞–º
        for duplicate in duplicates:
            if duplicate["type"] == "exact_bank_title":
                recommendations.append("‚ö†Ô∏è –ë–∞–Ω–∫–æ–≤—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è")
            elif duplicate["type"] == "similar_bank_title":
                recommendations.append(f"üìù –ü–æ—Ö–æ–∂–µ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ({duplicate['similarity']:.0%})")
            elif duplicate["type"] == "exact_profession_spec":
                recommendations.append("üîÑ –ü—Ä–æ—Ñ–µ—Å—Å–∏—è —Å —Ç–∞–∫–æ–π —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π —É–∂–µ –µ—Å—Ç—å")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ª–æ–≥–∏–∫–µ
        for issue in logic_analysis.get("issues", []):
            recommendations.append(f"ü§î {issue}")
        
        for suggestion in logic_analysis.get("suggestions", []):
            recommendations.append(f"üí° {suggestion}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤–µ–±-–ø–æ–∏—Å–∫—É
        if web_info.get("found"):
            recommendations.append(f"üåê {web_info.get('info', '–ù–∞–π–¥–µ–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è')}")
        
        return recommendations
    
    # === –ß–ê–¢ –° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ú ===
    
    async def chat_with_user(self, user_message: str, form_context: Dict[str, Any]) -> Dict[str, Any]:
        """–ß–∞—Ç —Å HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–º"""
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ñ–æ—Ä–º—ã
            form_analysis = await self.analyze_form_data(form_context)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            ai_response = await self._generate_chat_response(user_message, form_context, form_analysis)
            
            return {
                "message": ai_response,
                "analysis": form_analysis,
                "suggestions": self._generate_chat_suggestions(user_message, form_context)
            }
            
        except Exception as e:
            logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ —á–∞—Ç–∞: {e}")
            return {
                "message": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
                "analysis": {},
                "suggestions": []
            }
    
    async def _generate_chat_response(self, user_message: str, form_context: Dict[str, Any], form_analysis: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –≤ —á–∞—Ç–µ"""
        if not self.openai_client:
            return self._manual_chat_response(user_message, form_context)
        
        try:
            context = f"""
            –§–æ—Ä–º–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
            - –î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç: {form_context.get('department', '–ù–µ —É–∫–∞–∑–∞–Ω')}
            - –†–µ–∞–ª—å–Ω–∞—è –ø—Ä–æ—Ñ–µ—Å—Å–∏—è: {form_context.get('real_name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
            - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {form_context.get('specialization', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
            - –ë–∞–Ω–∫–æ–≤—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: {form_context.get('bank_title', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
            
            –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ä–º—ã:
            - –û—Ü–µ–Ω–∫–∞: {form_analysis.get('overall_score', 0.8):.1f}/1.0
            - –î—É–±–ª–∏–∫–∞—Ç—ã: {len(form_analysis.get('duplicates', []))}
            - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {len(form_analysis.get('recommendations', []))}
            
            –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_message}
            """
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "–¢—ã –ò–ò –ø–æ–º–æ—â–Ω–∏–∫ HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –≤ –±–∞–Ω–∫–µ Halyk Bank. –û—Ç–≤–µ—á–∞–µ—à—å –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. –ü–æ–º–æ–≥–∞–µ—à—å —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤."},
                    {"role": "user", "content": context}
                ],
                temperature=0.3,
                max_tokens=300
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"‚ùå HR Assistant: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return self._manual_chat_response(user_message, form_context)
    
    def _manual_chat_response(self, user_message: str, form_context: Dict[str, Any]) -> str:
        """–†—É—á–Ω–æ–π –æ—Ç–≤–µ—Ç (–∫–æ–≥–¥–∞ –ò–ò –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)"""
        if "–¥—É–±–ª–∏–∫–∞—Ç" in user_message.lower() or "–ø–æ—Ö–æ–∂" in user_message.lower():
            return "–ü—Ä–æ–≤–µ—Ä—è—é –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –±–∞–∑–µ... –ò–ò –ø–æ–º–æ—â–Ω–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
        
        if "–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç" in user_message.lower():
            return "–†–µ–∫–æ–º–µ–Ω–¥—É—é –≤—ã–±—Ä–∞—Ç—å –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –∏—Å—Ö–æ–¥—è –∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏."
        
        if "–Ω–∞–∑–≤–∞–Ω–∏–µ" in user_message.lower():
            return "–ë–∞–Ω–∫–æ–≤—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–º –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –±–∞–Ω–∫–∞."
        
        return "–ò–ò –ø–æ–º–æ—â–Ω–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ñ–æ—Ä–º—É —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ."
    
    def _generate_chat_suggestions(self, user_message: str, form_context: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è —á–∞—Ç–∞"""
        suggestions = []
        
        if not form_context.get("department"):
            suggestions.append("–ö–∞–∫–æ–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –≤—ã–±—Ä–∞—Ç—å?")
        
        if not form_context.get("real_name"):
            suggestions.append("–ö–∞–∫ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–∞–ª—å–Ω—É—é –ø—Ä–æ—Ñ–µ—Å—Å–∏—é?")
        
        if not form_context.get("bank_title"):
            suggestions.append("–ö–∞–∫ –Ω–∞–∑–≤–∞—Ç—å –ø—Ä–æ—Ñ–µ—Å—Å–∏—é –≤ –±–∞–Ω–∫–µ?")
        
        suggestions.extend(["–ï—Å—Ç—å –ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã?", "–í—Å—ë –ª–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ?"])
        
        return suggestions[:5]

# –≠–∫—Å–ø–æ—Ä—Ç –∫–ª–∞—Å—Å–∞
__all__ = ['HRAssistant']